<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Supervised Machine Learning | TAME 2.0: An Update to the TAME Toolkit for Introductory Data Science, Chemical-Biological Analyses, Machine Learning and Predictive Modeling, and Database Mining for Environmental Health Research</title>
  <meta name="description" content="This is an example of how the TAME 2.0 website will look, I hope!" />
  <meta name="generator" content="bookdown 0.40 and GitBook 2.6.7" />

  <meta property="og:title" content="Supervised Machine Learning | TAME 2.0: An Update to the TAME Toolkit for Introductory Data Science, Chemical-Biological Analyses, Machine Learning and Predictive Modeling, and Database Mining for Environmental Health Research" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="This is an example of how the TAME 2.0 website will look, I hope!" />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Supervised Machine Learning | TAME 2.0: An Update to the TAME Toolkit for Introductory Data Science, Chemical-Biological Analyses, Machine Learning and Predictive Modeling, and Database Mining for Environmental Health Research" />
  
  <meta name="twitter:description" content="This is an example of how the TAME 2.0 website will look, I hope!" />
  

<meta name="author" content="Rager Lab" />


<meta name="date" content="2024-10-01" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  <link rel="shortcut icon" href="Icons_Used_Throughout/Favicon.png" type="image/x-icon" />
<link rel="prev" href="introduction-to-artificial-intelligence-machine-learning-and-predictive-modeling-for-environmental-health.html"/>
<link rel="next" href="supervised-machine-learning-model-interpretation.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<link href="libs/htmltools-fill-0.5.8.1/fill.css" rel="stylesheet" />
<script src="libs/htmlwidgets-1.6.4/htmlwidgets.js"></script>
<link href="libs/datatables-css-0.0.0/datatables-crosstalk.css" rel="stylesheet" />
<script src="libs/datatables-binding-0.33/datatables.js"></script>
<link href="libs/dt-core-1.13.6/css/jquery.dataTables.min.css" rel="stylesheet" />
<link href="libs/dt-core-1.13.6/css/jquery.dataTables.extra.css" rel="stylesheet" />
<script src="libs/dt-core-1.13.6/js/jquery.dataTables.min.js"></script>
<link href="libs/crosstalk-1.2.1/css/crosstalk.min.css" rel="stylesheet" />
<script src="libs/crosstalk-1.2.1/js/crosstalk.min.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />
<link href="libs/tabwid-1.1.3/tabwid.css" rel="stylesheet" />
<script src="libs/tabwid-1.1.3/tabwid.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="toc-logo"><a href="./"><img src="Icons_Used_Throughout/TAME 2.0 Logo.png"><br></a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="part"><span><b>Chapter 1 Introductory <br>Data Science</b></span></li>
<li class="chapter" data-level="" data-path="fair-data-management-practices.html"><a href="fair-data-management-practices.html"><i class="fa fa-check"></i>FAIR Data Management Practices</a>
<ul>
<li class="chapter" data-level="" data-path="fair-data-management-practices.html"><a href="fair-data-management-practices.html#introduction-to-training-module"><i class="fa fa-check"></i>Introduction to Training Module</a></li>
<li class="chapter" data-level="" data-path="fair-data-management-practices.html"><a href="fair-data-management-practices.html#introduction-to-fair"><i class="fa fa-check"></i>Introduction to FAIR</a></li>
<li class="chapter" data-level="" data-path="fair-data-management-practices.html"><a href="fair-data-management-practices.html#breaking-down-fair-letter-by-letter"><i class="fa fa-check"></i>Breaking Down FAIR, Letter-by-Letter</a></li>
<li class="chapter" data-level="" data-path="fair-data-management-practices.html"><a href="fair-data-management-practices.html#what-does-this-mean-for-you"><i class="fa fa-check"></i>What Does This Mean for You?</a></li>
<li class="chapter" data-level="" data-path="fair-data-management-practices.html"><a href="fair-data-management-practices.html#data-repositories-for-sharing-of-data"><i class="fa fa-check"></i>Data Repositories for Sharing of Data</a></li>
<li class="chapter" data-level="" data-path="fair-data-management-practices.html"><a href="fair-data-management-practices.html#recent-shifts-in-regulatory-policies-for-data-sharing"><i class="fa fa-check"></i>Recent Shifts in Regulatory Policies for Data Sharing</a></li>
<li class="chapter" data-level="" data-path="fair-data-management-practices.html"><a href="fair-data-management-practices.html#additional-training-resources-on-fair"><i class="fa fa-check"></i>Additional Training Resources on FAIR</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="data-sharing-through-online-repositories.html"><a href="data-sharing-through-online-repositories.html"><i class="fa fa-check"></i>Data Sharing through Online Repositories</a>
<ul>
<li class="chapter" data-level="" data-path="data-sharing-through-online-repositories.html"><a href="data-sharing-through-online-repositories.html#an-overview-and-example-with-the-dataverse-repository"><i class="fa fa-check"></i>An Overview and Example with the Dataverse Repository</a></li>
<li class="chapter" data-level="" data-path="data-sharing-through-online-repositories.html"><a href="data-sharing-through-online-repositories.html#introduction-to-training-module-1"><i class="fa fa-check"></i>Introduction to Training Module</a></li>
<li class="chapter" data-level="" data-path="data-sharing-through-online-repositories.html"><a href="data-sharing-through-online-repositories.html#data-repositories"><i class="fa fa-check"></i>Data Repositories</a></li>
<li class="chapter" data-level="" data-path="data-sharing-through-online-repositories.html"><a href="data-sharing-through-online-repositories.html#the-dataverse-project"><i class="fa fa-check"></i>The Dataverse Project</a></li>
<li class="chapter" data-level="" data-path="data-sharing-through-online-repositories.html"><a href="data-sharing-through-online-repositories.html#what-is-a-dataverse"><i class="fa fa-check"></i>What is a Dataverse?</a></li>
<li class="chapter" data-level="" data-path="data-sharing-through-online-repositories.html"><a href="data-sharing-through-online-repositories.html#metadata"><i class="fa fa-check"></i>Metadata</a></li>
<li class="chapter" data-level="" data-path="data-sharing-through-online-repositories.html"><a href="data-sharing-through-online-repositories.html#creating-a-dataverse"><i class="fa fa-check"></i>Creating a Dataverse</a></li>
<li class="chapter" data-level="" data-path="data-sharing-through-online-repositories.html"><a href="data-sharing-through-online-repositories.html#creating-a-dataset"><i class="fa fa-check"></i>Creating a Dataset</a></li>
<li class="chapter" data-level="" data-path="data-sharing-through-online-repositories.html"><a href="data-sharing-through-online-repositories.html#concluding-remarks-1"><i class="fa fa-check"></i>Concluding Remarks</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="file-management-using-github.html"><a href="file-management-using-github.html"><i class="fa fa-check"></i>File Management using Github</a>
<ul>
<li class="chapter" data-level="" data-path="file-management-using-github.html"><a href="file-management-using-github.html#introduction-to-training-module-2"><i class="fa fa-check"></i>Introduction to Training Module</a></li>
<li class="chapter" data-level="" data-path="file-management-using-github.html"><a href="file-management-using-github.html#creating-an-account"><i class="fa fa-check"></i>Creating an Account</a></li>
<li class="chapter" data-level="" data-path="file-management-using-github.html"><a href="file-management-using-github.html#creating-a-repository"><i class="fa fa-check"></i>Creating a Repository</a></li>
<li class="chapter" data-level="" data-path="file-management-using-github.html"><a href="file-management-using-github.html#uploading-code"><i class="fa fa-check"></i>Uploading Code</a></li>
<li class="chapter" data-level="" data-path="file-management-using-github.html"><a href="file-management-using-github.html#adding-subfolders-in-a-repository"><i class="fa fa-check"></i>Adding Subfolders in a Repository</a></li>
<li class="chapter" data-level="" data-path="file-management-using-github.html"><a href="file-management-using-github.html#updating-code"><i class="fa fa-check"></i>Updating Code</a></li>
<li class="chapter" data-level="" data-path="file-management-using-github.html"><a href="file-management-using-github.html#updating-repository-titles-and-structure-to-support-a-manuscript"><i class="fa fa-check"></i>Updating Repository Titles and Structure to Support a Manuscript</a></li>
<li class="chapter" data-level="" data-path="file-management-using-github.html"><a href="file-management-using-github.html#tracking-code-changes-using-github-branches"><i class="fa fa-check"></i>Tracking Code Changes using Github Branches</a></li>
<li class="chapter" data-level="" data-path="file-management-using-github.html"><a href="file-management-using-github.html#concluding-remarks-2"><i class="fa fa-check"></i>Concluding Remarks</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="data-wrangling-in-excel.html"><a href="data-wrangling-in-excel.html"><i class="fa fa-check"></i>Data Wrangling in Excel</a>
<ul>
<li class="chapter" data-level="" data-path="data-wrangling-in-excel.html"><a href="data-wrangling-in-excel.html#introduction-to-training-module-3"><i class="fa fa-check"></i>Introduction to Training Module</a></li>
<li class="chapter" data-level="" data-path="data-wrangling-in-excel.html"><a href="data-wrangling-in-excel.html#save-a-copy-of-the-soon-to-be-organized-and-cleaned-dataset-as-a-new-file"><i class="fa fa-check"></i>Save a Copy of the Soon-To-Be Organized and Cleaned Dataset as a New File</a></li>
<li class="chapter" data-level="" data-path="data-wrangling-in-excel.html"><a href="data-wrangling-in-excel.html#remove-extraneous-white-space"><i class="fa fa-check"></i>Remove Extraneous White Space</a></li>
<li class="chapter" data-level="" data-path="data-wrangling-in-excel.html"><a href="data-wrangling-in-excel.html#replace-missing-data-with-na"><i class="fa fa-check"></i>Replace Missing Data with “NA”</a></li>
<li class="chapter" data-level="" data-path="data-wrangling-in-excel.html"><a href="data-wrangling-in-excel.html#create-a-metadata-tab"><i class="fa fa-check"></i>Create a Metadata Tab</a></li>
<li class="chapter" data-level="" data-path="data-wrangling-in-excel.html"><a href="data-wrangling-in-excel.html#abbreviate-and-capitalize-categorical-data"><i class="fa fa-check"></i>Abbreviate and Capitalize Categorical Data</a></li>
<li class="chapter" data-level="" data-path="data-wrangling-in-excel.html"><a href="data-wrangling-in-excel.html#alphabetize-sort-the-data-by-the-categorical-variable-of-interest"><i class="fa fa-check"></i>Alphabetize (Sort) the Data by the Categorical Variable of Interest</a></li>
<li class="chapter" data-level="" data-path="data-wrangling-in-excel.html"><a href="data-wrangling-in-excel.html#create-a-new-subject-number-column"><i class="fa fa-check"></i>Create a New Subject Number Column</a></li>
<li class="chapter" data-level="" data-path="data-wrangling-in-excel.html"><a href="data-wrangling-in-excel.html#remove-special-symbols-and-dashes"><i class="fa fa-check"></i>Remove Special Symbols and Dashes</a></li>
<li class="chapter" data-level="" data-path="data-wrangling-in-excel.html"><a href="data-wrangling-in-excel.html#bold-all-column-names-and-center-all-data"><i class="fa fa-check"></i>Bold all Column Names and Center all Data</a></li>
<li class="chapter" data-level="" data-path="data-wrangling-in-excel.html"><a href="data-wrangling-in-excel.html#create-a-subject-identifier-column"><i class="fa fa-check"></i>Create a Subject Identifier Column</a></li>
<li class="chapter" data-level="" data-path="data-wrangling-in-excel.html"><a href="data-wrangling-in-excel.html#separate-subject-demographic-data-from-experimental-measurements"><i class="fa fa-check"></i>Separate Subject Demographic Data from Experimental Measurements</a></li>
<li class="chapter" data-level="" data-path="data-wrangling-in-excel.html"><a href="data-wrangling-in-excel.html#convert-data-from-wide-to-long-format"><i class="fa fa-check"></i>Convert Data from Wide to Long Format</a></li>
<li class="chapter" data-level="" data-path="data-wrangling-in-excel.html"><a href="data-wrangling-in-excel.html#pivoting-data-from-a-wide-to-long-format"><i class="fa fa-check"></i>Pivoting Data from a Wide to Long Format</a></li>
<li class="chapter" data-level="" data-path="data-wrangling-in-excel.html"><a href="data-wrangling-in-excel.html#generating-summary-level-statistics-with-pivot-tables"><i class="fa fa-check"></i>Generating Summary-Level Statistics with Pivot Tables</a></li>
<li class="chapter" data-level="" data-path="data-wrangling-in-excel.html"><a href="data-wrangling-in-excel.html#excel-vs.-r-which-should-you-use"><i class="fa fa-check"></i>Excel vs. R: Which Should You Use?</a></li>
<li class="chapter" data-level="" data-path="data-wrangling-in-excel.html"><a href="data-wrangling-in-excel.html#concluding-remarks-3"><i class="fa fa-check"></i>Concluding Remarks</a></li>
</ul></li>
<li class="part"><span><b>Chapter 2 Coding in R</b></span></li>
<li class="chapter" data-level="" data-path="downloading-and-programming-in-r.html"><a href="downloading-and-programming-in-r.html"><i class="fa fa-check"></i>Downloading and Programming in R</a>
<ul>
<li class="chapter" data-level="" data-path="downloading-and-programming-in-r.html"><a href="downloading-and-programming-in-r.html#introduction-to-training-module-4"><i class="fa fa-check"></i>Introduction to Training Module</a></li>
<li class="chapter" data-level="" data-path="downloading-and-programming-in-r.html"><a href="downloading-and-programming-in-r.html#general-introduction-and-installation-of-r-and-rstudio"><i class="fa fa-check"></i>General Introduction and Installation of R and RStudio</a></li>
<li class="chapter" data-level="" data-path="downloading-and-programming-in-r.html"><a href="downloading-and-programming-in-r.html#introduction-to-r-packages"><i class="fa fa-check"></i>Introduction to R Packages</a></li>
<li class="chapter" data-level="" data-path="downloading-and-programming-in-r.html"><a href="downloading-and-programming-in-r.html#scripting-basics"><i class="fa fa-check"></i>Scripting Basics</a></li>
<li class="chapter" data-level="" data-path="downloading-and-programming-in-r.html"><a href="downloading-and-programming-in-r.html#code-troubleshooting"><i class="fa fa-check"></i>Code Troubleshooting</a></li>
<li class="chapter" data-level="" data-path="downloading-and-programming-in-r.html"><a href="downloading-and-programming-in-r.html#concluding-remarks-4"><i class="fa fa-check"></i>Concluding Remarks</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="coding-best-practices.html"><a href="coding-best-practices.html"><i class="fa fa-check"></i>Coding “Best” Practices</a>
<ul>
<li class="chapter" data-level="" data-path="coding-best-practices.html"><a href="coding-best-practices.html#introduction-to-training-module-5"><i class="fa fa-check"></i>Introduction to Training Module</a></li>
<li class="chapter" data-level="" data-path="coding-best-practices.html"><a href="coding-best-practices.html#scripting-file-types"><i class="fa fa-check"></i>Scripting File Types</a></li>
<li class="chapter" data-level="" data-path="coding-best-practices.html"><a href="coding-best-practices.html#script-headers-and-annotation"><i class="fa fa-check"></i>Script Headers and Annotation</a></li>
<li class="chapter" data-level="" data-path="coding-best-practices.html"><a href="coding-best-practices.html#coding-style"><i class="fa fa-check"></i>Coding Style</a></li>
<li class="chapter" data-level="" data-path="coding-best-practices.html"><a href="coding-best-practices.html#script-organization"><i class="fa fa-check"></i>Script Organization</a></li>
<li class="chapter" data-level="" data-path="coding-best-practices.html"><a href="coding-best-practices.html#concluding-remarks-5"><i class="fa fa-check"></i>Concluding Remarks</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="data-manipulation-and-reshaping.html"><a href="data-manipulation-and-reshaping.html"><i class="fa fa-check"></i>Data Manipulation and Reshaping</a>
<ul>
<li class="chapter" data-level="" data-path="data-manipulation-and-reshaping.html"><a href="data-manipulation-and-reshaping.html#introduction-to-training-module-6"><i class="fa fa-check"></i>Introduction to Training Module</a></li>
<li class="chapter" data-level="" data-path="data-manipulation-and-reshaping.html"><a href="data-manipulation-and-reshaping.html#data-manipulation-using-base-r"><i class="fa fa-check"></i>Data Manipulation Using Base R</a></li>
<li class="chapter" data-level="" data-path="data-manipulation-and-reshaping.html"><a href="data-manipulation-and-reshaping.html#introduction-to-tidyverse"><i class="fa fa-check"></i>Introduction to Tidyverse</a></li>
<li class="chapter" data-level="" data-path="data-manipulation-and-reshaping.html"><a href="data-manipulation-and-reshaping.html#concluding-remarks-6"><i class="fa fa-check"></i>Concluding Remarks</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="improving-coding-efficiencies.html"><a href="improving-coding-efficiencies.html"><i class="fa fa-check"></i>Improving Coding Efficiencies</a>
<ul>
<li class="chapter" data-level="" data-path="improving-coding-efficiencies.html"><a href="improving-coding-efficiencies.html#introduction-to-training-module-7"><i class="fa fa-check"></i>Introduction to Training Module</a></li>
<li class="chapter" data-level="" data-path="improving-coding-efficiencies.html"><a href="improving-coding-efficiencies.html#loops"><i class="fa fa-check"></i>Loops</a></li>
<li class="chapter" data-level="" data-path="improving-coding-efficiencies.html"><a href="improving-coding-efficiencies.html#functions"><i class="fa fa-check"></i>Functions</a></li>
<li class="chapter" data-level="" data-path="improving-coding-efficiencies.html"><a href="improving-coding-efficiencies.html#list-operations"><i class="fa fa-check"></i>List operations</a></li>
<li class="chapter" data-level="" data-path="improving-coding-efficiencies.html"><a href="improving-coding-efficiencies.html#concluding-remarks-7"><i class="fa fa-check"></i>Concluding Remarks</a></li>
<li class="chapter" data-level="" data-path="improving-coding-efficiencies.html"><a href="improving-coding-efficiencies.html#additional-resources-2"><i class="fa fa-check"></i>Additional Resources</a></li>
</ul></li>
<li class="part"><span><b>Chapter 3 Basics of <br>Data Analysis and Visualizations</b></span></li>
<li class="chapter" data-level="" data-path="data-visualizations.html"><a href="data-visualizations.html"><i class="fa fa-check"></i>Data Visualizations</a>
<ul>
<li class="chapter" data-level="" data-path="data-visualizations.html"><a href="data-visualizations.html#introduction-to-data-visualizations"><i class="fa fa-check"></i>Introduction to Data Visualizations</a></li>
<li class="chapter" data-level="" data-path="data-visualizations.html"><a href="data-visualizations.html#introduction-to-training-module-8"><i class="fa fa-check"></i>Introduction to Training Module</a></li>
<li class="chapter" data-level="" data-path="data-visualizations.html"><a href="data-visualizations.html#density-plot-visualization"><i class="fa fa-check"></i>Density Plot Visualization</a></li>
<li class="chapter" data-level="" data-path="data-visualizations.html"><a href="data-visualizations.html#boxplot-visualization"><i class="fa fa-check"></i>Boxplot Visualization</a></li>
<li class="chapter" data-level="" data-path="data-visualizations.html"><a href="data-visualizations.html#correlation-visualizations"><i class="fa fa-check"></i>Correlation Visualizations</a></li>
<li class="chapter" data-level="" data-path="data-visualizations.html"><a href="data-visualizations.html#heatmap-visualization"><i class="fa fa-check"></i>Heatmap Visualization</a></li>
<li class="chapter" data-level="" data-path="data-visualizations.html"><a href="data-visualizations.html#concluding-remarks-8"><i class="fa fa-check"></i>Concluding Remarks</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="improving-data-visualizations.html"><a href="improving-data-visualizations.html"><i class="fa fa-check"></i>Improving Data Visualizations</a>
<ul>
<li class="chapter" data-level="" data-path="improving-data-visualizations.html"><a href="improving-data-visualizations.html#introduction-to-data-visulization-conventions"><i class="fa fa-check"></i>Introduction to Data Visulization Conventions</a></li>
<li class="chapter" data-level="" data-path="improving-data-visualizations.html"><a href="improving-data-visualizations.html#introduction-to-training-module-9"><i class="fa fa-check"></i>Introduction to Training Module</a></li>
<li class="chapter" data-level="" data-path="improving-data-visualizations.html"><a href="improving-data-visualizations.html#creating-an-improved-boxplot-visualization"><i class="fa fa-check"></i>Creating an Improved Boxplot Visualization</a></li>
<li class="chapter" data-level="" data-path="improving-data-visualizations.html"><a href="improving-data-visualizations.html#creating-an-improved-heatmap-visualization"><i class="fa fa-check"></i>Creating an Improved Heatmap Visualization</a></li>
<li class="chapter" data-level="" data-path="improving-data-visualizations.html"><a href="improving-data-visualizations.html#creating-multi-plot-figures"><i class="fa fa-check"></i>Creating Multi-Plot Figures</a></li>
<li class="chapter" data-level="" data-path="improving-data-visualizations.html"><a href="improving-data-visualizations.html#concluding-remarks-9"><i class="fa fa-check"></i>Concluding Remarks</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="normality-tests-and-data-transformations.html"><a href="normality-tests-and-data-transformations.html"><i class="fa fa-check"></i>Normality Tests and Data Transformations</a>
<ul>
<li class="chapter" data-level="" data-path="normality-tests-and-data-transformations.html"><a href="normality-tests-and-data-transformations.html#introduction-to-training-module-10"><i class="fa fa-check"></i>Introduction to Training Module</a></li>
<li class="chapter" data-level="" data-path="normality-tests-and-data-transformations.html"><a href="normality-tests-and-data-transformations.html#what-is-a-normal-distribution"><i class="fa fa-check"></i>What is a Normal Distribution?</a></li>
<li class="chapter" data-level="" data-path="normality-tests-and-data-transformations.html"><a href="normality-tests-and-data-transformations.html#qualitative-assessment-of-normality"><i class="fa fa-check"></i>Qualitative Assessment of Normality</a></li>
<li class="chapter" data-level="" data-path="normality-tests-and-data-transformations.html"><a href="normality-tests-and-data-transformations.html#quantitative-normality-assessment"><i class="fa fa-check"></i>Quantitative Normality Assessment</a></li>
<li class="chapter" data-level="" data-path="normality-tests-and-data-transformations.html"><a href="normality-tests-and-data-transformations.html#data-transformation"><i class="fa fa-check"></i>Data Transformation</a></li>
<li class="chapter" data-level="" data-path="normality-tests-and-data-transformations.html"><a href="normality-tests-and-data-transformations.html#additional-considerations-regarding-normality"><i class="fa fa-check"></i>Additional Considerations Regarding Normality</a></li>
<li class="chapter" data-level="" data-path="normality-tests-and-data-transformations.html"><a href="normality-tests-and-data-transformations.html#concluding-remarks-10"><i class="fa fa-check"></i>Concluding Remarks</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="intoduction-to-statistical-tests.html"><a href="intoduction-to-statistical-tests.html"><i class="fa fa-check"></i>Intoduction to Statistical Tests</a>
<ul>
<li class="chapter" data-level="" data-path="intoduction-to-statistical-tests.html"><a href="intoduction-to-statistical-tests.html#introduction-to-training-module-11"><i class="fa fa-check"></i>Introduction to Training Module</a></li>
<li class="chapter" data-level="" data-path="intoduction-to-statistical-tests.html"><a href="intoduction-to-statistical-tests.html#assessing-normality-homogeneity-of-variance"><i class="fa fa-check"></i>Assessing Normality &amp; Homogeneity of Variance</a></li>
<li class="chapter" data-level="" data-path="intoduction-to-statistical-tests.html"><a href="intoduction-to-statistical-tests.html#two-group-visualizations-and-statistical-comparisons-using-the-t-test"><i class="fa fa-check"></i>Two-Group Visualizations and Statistical Comparisons using the T-Test</a></li>
<li class="chapter" data-level="" data-path="intoduction-to-statistical-tests.html"><a href="intoduction-to-statistical-tests.html#three-group-visualizations-and-statistical-comparisons-using-an-anova"><i class="fa fa-check"></i>Three-Group Visualizations and Statistical Comparisons using an ANOVA</a></li>
<li class="chapter" data-level="" data-path="intoduction-to-statistical-tests.html"><a href="intoduction-to-statistical-tests.html#regression-modeling-and-visualization-linear-and-logistic-regressions"><i class="fa fa-check"></i>Regression Modeling and Visualization: Linear and Logistic Regressions</a></li>
<li class="chapter" data-level="" data-path="intoduction-to-statistical-tests.html"><a href="intoduction-to-statistical-tests.html#statistical-evaluations-of-categorical-data-using-the-chi-squared-test-and-fishers-exact-test"><i class="fa fa-check"></i>Statistical Evaluations of Categorical Data using the Chi-Squared Test and Fisher’s Exact Test</a></li>
<li class="chapter" data-level="" data-path="intoduction-to-statistical-tests.html"><a href="intoduction-to-statistical-tests.html#concluding-remarks-11"><i class="fa fa-check"></i>Concluding Remarks</a></li>
</ul></li>
<li class="part"><span><b>Chapter 4 Converting Wet Lab Data into Dry Lab Analyses</b></span></li>
<li class="chapter" data-level="" data-path="overview-of-experimental-design-and-example-data.html"><a href="overview-of-experimental-design-and-example-data.html"><i class="fa fa-check"></i>Overview of Experimental Design and Example Data</a>
<ul>
<li class="chapter" data-level="" data-path="overview-of-experimental-design-and-example-data.html"><a href="overview-of-experimental-design-and-example-data.html#introduction-to-training-module-12"><i class="fa fa-check"></i>Introduction to Training Module</a></li>
<li class="chapter" data-level="" data-path="overview-of-experimental-design-and-example-data.html"><a href="overview-of-experimental-design-and-example-data.html#replicates"><i class="fa fa-check"></i>Replicates</a></li>
<li class="chapter" data-level="" data-path="overview-of-experimental-design-and-example-data.html"><a href="overview-of-experimental-design-and-example-data.html#orientation-to-example-data-for-chapter-4"><i class="fa fa-check"></i>Orientation to Example Data for Chapter 4</a></li>
<li class="chapter" data-level="" data-path="overview-of-experimental-design-and-example-data.html"><a href="overview-of-experimental-design-and-example-data.html#concluding-remarks-12"><i class="fa fa-check"></i>Concluding Remarks</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="data-import-processing-and-summary-statistics.html"><a href="data-import-processing-and-summary-statistics.html"><i class="fa fa-check"></i>Data Import, Processing, and Summary Statistics</a>
<ul>
<li class="chapter" data-level="" data-path="data-import-processing-and-summary-statistics.html"><a href="data-import-processing-and-summary-statistics.html#introduction-to-training-module-13"><i class="fa fa-check"></i>Introduction to Training Module</a></li>
<li class="chapter" data-level="" data-path="data-import-processing-and-summary-statistics.html"><a href="data-import-processing-and-summary-statistics.html#data-import"><i class="fa fa-check"></i>Data Import</a></li>
<li class="chapter" data-level="" data-path="data-import-processing-and-summary-statistics.html"><a href="data-import-processing-and-summary-statistics.html#handling-missing-values"><i class="fa fa-check"></i>Handling Missing Values</a></li>
<li class="chapter" data-level="" data-path="data-import-processing-and-summary-statistics.html"><a href="data-import-processing-and-summary-statistics.html#averaging-replicates"><i class="fa fa-check"></i>Averaging Replicates</a></li>
<li class="chapter" data-level="" data-path="data-import-processing-and-summary-statistics.html"><a href="data-import-processing-and-summary-statistics.html#descriptive-statistics"><i class="fa fa-check"></i>Descriptive Statistics</a></li>
<li class="chapter" data-level="" data-path="data-import-processing-and-summary-statistics.html"><a href="data-import-processing-and-summary-statistics.html#normality-assessment-and-data-transformation"><i class="fa fa-check"></i>Normality Assessment and Data Transformation</a></li>
<li class="chapter" data-level="" data-path="data-import-processing-and-summary-statistics.html"><a href="data-import-processing-and-summary-statistics.html#concluding-remarks-13"><i class="fa fa-check"></i>Concluding Remarks</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="data-import-from-pdf-sources.html"><a href="data-import-from-pdf-sources.html"><i class="fa fa-check"></i>Data Import from PDF Sources</a>
<ul>
<li class="chapter" data-level="" data-path="data-import-from-pdf-sources.html"><a href="data-import-from-pdf-sources.html#introduction-to-training-module-14"><i class="fa fa-check"></i>Introduction to Training Module</a></li>
<li class="chapter" data-level="" data-path="data-import-from-pdf-sources.html"><a href="data-import-from-pdf-sources.html#importing-data-from-many-single-pdfs-with-the-same-formatting"><i class="fa fa-check"></i>Importing Data from Many Single PDFs with the Same Formatting</a></li>
<li class="chapter" data-level="" data-path="data-import-from-pdf-sources.html"><a href="data-import-from-pdf-sources.html#importing-data-stored-in-pdf-tables"><i class="fa fa-check"></i>Importing Data Stored in PDF Tables</a></li>
<li class="chapter" data-level="" data-path="data-import-from-pdf-sources.html"><a href="data-import-from-pdf-sources.html#concluding-remarks-14"><i class="fa fa-check"></i>Concluding Remarks</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="two-group-comparisons-and-visualizations.html"><a href="two-group-comparisons-and-visualizations.html"><i class="fa fa-check"></i>Two-Group Comparisons and Visualizations</a>
<ul>
<li class="chapter" data-level="" data-path="two-group-comparisons-and-visualizations.html"><a href="two-group-comparisons-and-visualizations.html#introduction-to-training-module-15"><i class="fa fa-check"></i>Introduction to Training Module</a></li>
<li class="chapter" data-level="" data-path="two-group-comparisons-and-visualizations.html"><a href="two-group-comparisons-and-visualizations.html#overview-of-two-group-statistical-tests"><i class="fa fa-check"></i>Overview of Two Group Statistical Tests</a></li>
<li class="chapter" data-level="" data-path="two-group-comparisons-and-visualizations.html"><a href="two-group-comparisons-and-visualizations.html#statistical-vs-biological-significance"><i class="fa fa-check"></i>Statistical vs Biological Significance</a></li>
<li class="chapter" data-level="" data-path="two-group-comparisons-and-visualizations.html"><a href="two-group-comparisons-and-visualizations.html#unpaired-test-example"><i class="fa fa-check"></i>Unpaired Test Example</a></li>
<li class="chapter" data-level="" data-path="two-group-comparisons-and-visualizations.html"><a href="two-group-comparisons-and-visualizations.html#paired-test-example"><i class="fa fa-check"></i>Paired Test Example</a></li>
<li class="chapter" data-level="" data-path="two-group-comparisons-and-visualizations.html"><a href="two-group-comparisons-and-visualizations.html#visualizing-results"><i class="fa fa-check"></i>Visualizing Results</a></li>
<li class="chapter" data-level="" data-path="two-group-comparisons-and-visualizations.html"><a href="two-group-comparisons-and-visualizations.html#concluding-remarks-15"><i class="fa fa-check"></i>Concluding Remarks</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="multi-group-and-multi-variable-comparisons-and-visualizations.html"><a href="multi-group-and-multi-variable-comparisons-and-visualizations.html"><i class="fa fa-check"></i>Multi-Group and Multi-Variable Comparisons and Visualizations</a>
<ul>
<li class="chapter" data-level="" data-path="multi-group-and-multi-variable-comparisons-and-visualizations.html"><a href="multi-group-and-multi-variable-comparisons-and-visualizations.html#introduction-to-training-module-16"><i class="fa fa-check"></i>Introduction to Training Module</a></li>
<li class="chapter" data-level="" data-path="multi-group-and-multi-variable-comparisons-and-visualizations.html"><a href="multi-group-and-multi-variable-comparisons-and-visualizations.html#overview-of-multi-group-statistical-tests"><i class="fa fa-check"></i>Overview of Multi-Group Statistical Tests</a></li>
<li class="chapter" data-level="" data-path="multi-group-and-multi-variable-comparisons-and-visualizations.html"><a href="multi-group-and-multi-variable-comparisons-and-visualizations.html#multi-group-analysis-example"><i class="fa fa-check"></i>Multi-Group Analysis Example</a></li>
<li class="chapter" data-level="" data-path="multi-group-and-multi-variable-comparisons-and-visualizations.html"><a href="multi-group-and-multi-variable-comparisons-and-visualizations.html#visualization-of-multi-group-statistical-results"><i class="fa fa-check"></i>Visualization of Multi-Group Statistical Results</a></li>
<li class="chapter" data-level="" data-path="multi-group-and-multi-variable-comparisons-and-visualizations.html"><a href="multi-group-and-multi-variable-comparisons-and-visualizations.html#concluding-remarks-16"><i class="fa fa-check"></i>Concluding Remarks</a></li>
</ul></li>
<li class="part"><span><b>Chapter 5 Machine Learning &amp; Artificial Intelligence</b></span></li>
<li class="chapter" data-level="" data-path="introduction-to-artificial-intelligence-machine-learning-and-predictive-modeling-for-environmental-health.html"><a href="introduction-to-artificial-intelligence-machine-learning-and-predictive-modeling-for-environmental-health.html"><i class="fa fa-check"></i>Introduction to Artificial Intelligence, Machine Learning, and Predictive Modeling for Environmental Health</a>
<ul>
<li class="chapter" data-level="" data-path="introduction-to-artificial-intelligence-machine-learning-and-predictive-modeling-for-environmental-health.html"><a href="introduction-to-artificial-intelligence-machine-learning-and-predictive-modeling-for-environmental-health.html#introduction-to-training-module-17"><i class="fa fa-check"></i>Introduction to Training Module</a></li>
<li class="chapter" data-level="" data-path="introduction-to-artificial-intelligence-machine-learning-and-predictive-modeling-for-environmental-health.html"><a href="introduction-to-artificial-intelligence-machine-learning-and-predictive-modeling-for-environmental-health.html#general-historical-context-and-taxonomy-of-modern-aiml"><i class="fa fa-check"></i>General Historical Context and Taxonomy of Modern AI/ML</a></li>
<li class="chapter" data-level="" data-path="introduction-to-artificial-intelligence-machine-learning-and-predictive-modeling-for-environmental-health.html"><a href="introduction-to-artificial-intelligence-machine-learning-and-predictive-modeling-for-environmental-health.html#application-of-machine-learning-in-environmental-health-science"><i class="fa fa-check"></i>Application of Machine Learning in Environmental Health Science</a></li>
<li class="chapter" data-level="" data-path="introduction-to-artificial-intelligence-machine-learning-and-predictive-modeling-for-environmental-health.html"><a href="introduction-to-artificial-intelligence-machine-learning-and-predictive-modeling-for-environmental-health.html#concluding-remarks-17"><i class="fa fa-check"></i>Concluding Remarks</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="supervised-machine-learning.html"><a href="supervised-machine-learning.html"><i class="fa fa-check"></i>Supervised Machine Learning</a>
<ul>
<li class="chapter" data-level="" data-path="supervised-machine-learning.html"><a href="supervised-machine-learning.html#introduction-to-training-module-18"><i class="fa fa-check"></i>Introduction to Training Module</a></li>
<li class="chapter" data-level="" data-path="supervised-machine-learning.html"><a href="supervised-machine-learning.html#types-of-machine-learning"><i class="fa fa-check"></i>Types of Machine Learning</a></li>
<li class="chapter" data-level="" data-path="supervised-machine-learning.html"><a href="supervised-machine-learning.html#types-of-supervised-machine-learning-algorithms"><i class="fa fa-check"></i>Types of Supervised Machine Learning Algorithms</a></li>
<li class="chapter" data-level="" data-path="supervised-machine-learning.html"><a href="supervised-machine-learning.html#training-supervised-machine-learning-models"><i class="fa fa-check"></i>Training Supervised Machine Learning Models</a></li>
<li class="chapter" data-level="" data-path="supervised-machine-learning.html"><a href="supervised-machine-learning.html#assessing-classification-based-model-performance"><i class="fa fa-check"></i>Assessing Classification-Based Model Performance</a></li>
<li class="chapter" data-level="" data-path="supervised-machine-learning.html"><a href="supervised-machine-learning.html#introduction-to-activity-and-example-dataset"><i class="fa fa-check"></i>Introduction to Activity and Example Dataset</a></li>
<li class="chapter" data-level="" data-path="supervised-machine-learning.html"><a href="supervised-machine-learning.html#testing-for-differences-in-predictor-variables-across-the-outcome-classes"><i class="fa fa-check"></i>Testing for Differences in Predictor Variables across the Outcome Classes</a></li>
<li class="chapter" data-level="" data-path="supervised-machine-learning.html"><a href="supervised-machine-learning.html#predicting-ias-detection-with-a-random-forest-rf-model"><i class="fa fa-check"></i>Predicting iAs Detection with a Random Forest (RF) Model</a></li>
<li class="chapter" data-level="" data-path="supervised-machine-learning.html"><a href="supervised-machine-learning.html#class-imbalance"><i class="fa fa-check"></i>Class Imbalance</a></li>
<li class="chapter" data-level="" data-path="supervised-machine-learning.html"><a href="supervised-machine-learning.html#concluding-remarks-18"><i class="fa fa-check"></i>Concluding Remarks</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="supervised-machine-learning-model-interpretation.html"><a href="supervised-machine-learning-model-interpretation.html"><i class="fa fa-check"></i>Supervised Machine Learning Model Interpretation</a>
<ul>
<li class="chapter" data-level="" data-path="supervised-machine-learning-model-interpretation.html"><a href="supervised-machine-learning-model-interpretation.html#introduction-to-training-module-19"><i class="fa fa-check"></i>Introduction to Training Module</a></li>
<li class="chapter" data-level="" data-path="supervised-machine-learning-model-interpretation.html"><a href="supervised-machine-learning-model-interpretation.html#variable-importance"><i class="fa fa-check"></i>Variable Importance</a></li>
<li class="chapter" data-level="" data-path="supervised-machine-learning-model-interpretation.html"><a href="supervised-machine-learning-model-interpretation.html#decision-boundary"><i class="fa fa-check"></i>Decision Boundary</a></li>
<li class="chapter" data-level="" data-path="supervised-machine-learning-model-interpretation.html"><a href="supervised-machine-learning-model-interpretation.html#introduction-to-example-dataset-and-activity"><i class="fa fa-check"></i>Introduction to Example Dataset and Activity</a></li>
<li class="chapter" data-level="" data-path="supervised-machine-learning-model-interpretation.html"><a href="supervised-machine-learning-model-interpretation.html#predicting-ias-detection-with-a-random-forest-rf-model-1"><i class="fa fa-check"></i>Predicting iAs Detection with a Random Forest (RF) Model</a></li>
<li class="chapter" data-level="" data-path="supervised-machine-learning-model-interpretation.html"><a href="supervised-machine-learning-model-interpretation.html#variable-importance-plot"><i class="fa fa-check"></i>Variable Importance Plot</a></li>
<li class="chapter" data-level="" data-path="supervised-machine-learning-model-interpretation.html"><a href="supervised-machine-learning-model-interpretation.html#decision-boundary-plot"><i class="fa fa-check"></i>Decision Boundary Plot</a></li>
<li class="chapter" data-level="" data-path="supervised-machine-learning-model-interpretation.html"><a href="supervised-machine-learning-model-interpretation.html#decision-boundary-plot-incorporating-smote"><i class="fa fa-check"></i>Decision Boundary Plot Incorporating SMOTE</a></li>
<li class="chapter" data-level="" data-path="supervised-machine-learning-model-interpretation.html"><a href="supervised-machine-learning-model-interpretation.html#concluding-remarks-19"><i class="fa fa-check"></i>Concluding Remarks</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="unsupervised-machine-learning-part-1-k-means-clustering-pca.html"><a href="unsupervised-machine-learning-part-1-k-means-clustering-pca.html"><i class="fa fa-check"></i>Unsupervised Machine Learning Part 1: K-Means Clustering &amp; PCA</a>
<ul>
<li class="chapter" data-level="" data-path="unsupervised-machine-learning-part-1-k-means-clustering-pca.html"><a href="unsupervised-machine-learning-part-1-k-means-clustering-pca.html#introduction-to-training-module-20"><i class="fa fa-check"></i>Introduction to Training Module</a></li>
<li class="chapter" data-level="" data-path="unsupervised-machine-learning-part-1-k-means-clustering-pca.html"><a href="unsupervised-machine-learning-part-1-k-means-clustering-pca.html#introduction-to-unsupervised-machine-learning"><i class="fa fa-check"></i>Introduction to Unsupervised Machine Learning</a></li>
<li class="chapter" data-level="" data-path="unsupervised-machine-learning-part-1-k-means-clustering-pca.html"><a href="unsupervised-machine-learning-part-1-k-means-clustering-pca.html#introduction-to-example-data"><i class="fa fa-check"></i>Introduction to Example Data</a></li>
<li class="chapter" data-level="" data-path="unsupervised-machine-learning-part-1-k-means-clustering-pca.html"><a href="unsupervised-machine-learning-part-1-k-means-clustering-pca.html#identifying-clusters-of-chemicals-through-k-means"><i class="fa fa-check"></i>Identifying Clusters of Chemicals through <em>K</em>-Means</a></li>
<li class="chapter" data-level="" data-path="unsupervised-machine-learning-part-1-k-means-clustering-pca.html"><a href="unsupervised-machine-learning-part-1-k-means-clustering-pca.html#principal-component-analysis-pca-1"><i class="fa fa-check"></i>Principal Component Analysis (PCA)</a></li>
<li class="chapter" data-level="" data-path="unsupervised-machine-learning-part-1-k-means-clustering-pca.html"><a href="unsupervised-machine-learning-part-1-k-means-clustering-pca.html#incorporating-k-means-into-pca-for-predictive-modeling"><i class="fa fa-check"></i>Incorporating <em>K</em>-Means into PCA for Predictive Modeling</a></li>
<li class="chapter" data-level="" data-path="unsupervised-machine-learning-part-1-k-means-clustering-pca.html"><a href="unsupervised-machine-learning-part-1-k-means-clustering-pca.html#concluding-remarks-20"><i class="fa fa-check"></i>Concluding Remarks</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="unsupervised-machine-learning-part-2-additional-clustering-applications.html"><a href="unsupervised-machine-learning-part-2-additional-clustering-applications.html"><i class="fa fa-check"></i>Unsupervised Machine Learning Part 2: Additional Clustering Applications</a>
<ul>
<li class="chapter" data-level="" data-path="unsupervised-machine-learning-part-2-additional-clustering-applications.html"><a href="unsupervised-machine-learning-part-2-additional-clustering-applications.html#introduction-to-training-module-21"><i class="fa fa-check"></i>Introduction to Training Module</a></li>
<li class="chapter" data-level="" data-path="unsupervised-machine-learning-part-2-additional-clustering-applications.html"><a href="unsupervised-machine-learning-part-2-additional-clustering-applications.html#k-means-clustering-1"><i class="fa fa-check"></i><em>K</em>-Means Clustering</a></li>
<li class="chapter" data-level="" data-path="unsupervised-machine-learning-part-2-additional-clustering-applications.html"><a href="unsupervised-machine-learning-part-2-additional-clustering-applications.html#hierarchical-clustering"><i class="fa fa-check"></i>Hierarchical Clustering</a></li>
<li class="chapter" data-level="" data-path="unsupervised-machine-learning-part-2-additional-clustering-applications.html"><a href="unsupervised-machine-learning-part-2-additional-clustering-applications.html#introduction-to-example-data-1"><i class="fa fa-check"></i>Introduction to Example Data</a></li>
<li class="chapter" data-level="" data-path="unsupervised-machine-learning-part-2-additional-clustering-applications.html"><a href="unsupervised-machine-learning-part-2-additional-clustering-applications.html#hierarchical-clustering-1"><i class="fa fa-check"></i>Hierarchical Clustering</a></li>
<li class="chapter" data-level="" data-path="unsupervised-machine-learning-part-2-additional-clustering-applications.html"><a href="unsupervised-machine-learning-part-2-additional-clustering-applications.html#clustering-plot"><i class="fa fa-check"></i>Clustering Plot</a></li>
<li class="chapter" data-level="" data-path="unsupervised-machine-learning-part-2-additional-clustering-applications.html"><a href="unsupervised-machine-learning-part-2-additional-clustering-applications.html#hierarchical-clustering-visualization"><i class="fa fa-check"></i>Hierarchical Clustering Visualization</a></li>
<li class="chapter" data-level="" data-path="unsupervised-machine-learning-part-2-additional-clustering-applications.html"><a href="unsupervised-machine-learning-part-2-additional-clustering-applications.html#variable-contributions"><i class="fa fa-check"></i>Variable Contributions</a></li>
<li class="chapter" data-level="" data-path="unsupervised-machine-learning-part-2-additional-clustering-applications.html"><a href="unsupervised-machine-learning-part-2-additional-clustering-applications.html#concluding-remarks-21"><i class="fa fa-check"></i>Concluding Remarks</a></li>
</ul></li>
<li class="part"><span><b>Chapter 6 Applications in Toxicology &amp; Exposure Science</b></span></li>
<li class="part"><span><b>Chapter 7 Environmental Health Database Mining</b></span></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">TAME 2.0: An Update to the TAME Toolkit for Introductory Data Science, Chemical-Biological Analyses, Machine Learning and Predictive Modeling, and Database Mining for Environmental Health Research</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="supervised-machine-learning" class="section level1 hasAnchor">
<h1>Supervised Machine Learning<a href="supervised-machine-learning.html#supervised-machine-learning" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>This training module was developed by Alexis Payton, Oyemwenosa N. Avenbuan, Lauren E. Koval, and Julia E. Rager.</p>
<p>All input files (script, data, and figures) can be downloaded from the <a href="https://github.com/UNCSRP/TAME2">UNC-SRP TAME2 GitHub website</a>.</p>
<div id="introduction-to-training-module-18" class="section level2 hasAnchor">
<h2>Introduction to Training Module<a href="supervised-machine-learning.html#introduction-to-training-module-18" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Machine learning is a field that has been around for decades but has exploded in popularity and utility in recent years due to the proliferation of big and/or high dimensional data. Machine learning has the ability to sift through and learn from large volumes of data and use that knowledge to solve problems. The challenges of high dimensional data as they pertain to environmental health and the applications of machine learning to mitigate some of those challenges are discussed further in <a href="https://www.frontiersin.org/articles/10.3389/ftox.2023.1171175/full">Payton et. al</a>. In this module, we will introduce different types of machine learning and then focus in on supervised machine learning, including how to train and assess supervised machine learning models. We will then analyze an example dataset with supervised machine learning highlighting an example with random forest modeling.</p>
<p><br></p>
</div>
<div id="types-of-machine-learning" class="section level2 hasAnchor">
<h2>Types of Machine Learning<a href="supervised-machine-learning.html#types-of-machine-learning" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Within the field of machine learning, there are many different types of algorithms that can be leveraged to address environmental health research questions. The two broad categories of machine learning frequently applied to environmental health research are: (1) supervised machine learning and (2) unsupervised machine learning.</p>
<p><strong>Supervised machine learning</strong> involves training a model using a labeled dataset, where each independent or predictor variable is associated with a dependent variable with a known outcome. This allows the model to learn how to predict the labeled outcome on data it hasn’t “seen” before based on the patterns and relationships it previously identified in the data. For example, supervised machine learning has been used for cancer prediction and prognosis based on variables like tumor size, stage, and age (<a href="https://www.sciencedirect.com/science/article/abs/pii/S1386505617302368?via%3Dihub">Lynch et. al</a>, <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7416093/">Asadi et. al</a>).</p>
<p>Supervised machine learning includes:</p>
<ul>
<li>Classification: Using algorithms to classify a categorical outcome (ie. plant species, disease status, etc.)</li>
<li>Regression: Using algorithms to predict a continuous outcome (ie. gene expression, chemical concentration, etc.)
<img src="Module5_2_Input/Module5_2_Image1.png" width="700" style="display: block; margin: auto;" />
<center>
Soni, D. (2018, March 22). Supervised vs. Unsupervised Learning. Towards Data Science; Towards Data Science. <a href="https://towardsdatascience.com/supervised-vs-unsupervised-learning-14f68e32ea8d" class="uri">https://towardsdatascience.com/supervised-vs-unsupervised-learning-14f68e32ea8d</a>
</center></li>
</ul>
<p><strong>Unsupervised machine learning</strong>, on the other hand, involves using models to find patterns or associations between variables in a dataset that lacks a known or labeled outcome. For example, unsupervised machine learning has been used to identify new patterns across genes that are co-expressed, informing potential biological pathways mediating human disease (<a href="https://bmcsystbiol.biomedcentral.com/articles/10.1186/s12918-017-0420-6">Botía et. al</a>, <a href="https://www.sciencedirect.com/science/article/pii/S0888754317300575?via%3Dihub">Pagnuco et. al</a>).</p>
<img src="Module5_2_Input/Module5_2_Image2.png" width="75%" style="display: block; margin: auto;" />
<center>
Langs, G., Röhrich, S., Hofmanninger, J., Prayer, F., Pan, J., Herold, C., &amp; Prosch, H. (2018). Machine learning: from radiomics to discovery and routine. Der Radiologe, 58(S1), 1–6. PMID: <a href="https://doi.org/10.1007/s00117-018-0407-3">34013136</a>. Figure regenerated here in alignment with its published <a href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution 4.0 International License</a>.
</center>
<p>Overall, the distinction between supervised and unsupervised learning is an important concept in machine learning, as it can inform the choice of algorithms and techniques used to analyze and make predictions from data. It is worth noting that there are also other types of machine learning, such as <a href="https://www.altexsoft.com/blog/semi-supervised-learning/">semi-supervised learning</a>, <a href="https://www.geeksforgeeks.org/what-is-reinforcement-learning/">reinforcement learning</a>, and <a href="https://www.geeksforgeeks.org/introduction-deep-learning/">deep learning</a>, though we will not further discuss these topics in this module.</p>
<p><br></p>
</div>
<div id="types-of-supervised-machine-learning-algorithms" class="section level2 hasAnchor">
<h2>Types of Supervised Machine Learning Algorithms<a href="supervised-machine-learning.html#types-of-supervised-machine-learning-algorithms" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Although this module’s example will focus on a random forest model in the coding example below, other commonly used algorithms for supervised machine learning include:</p>
<ul>
<li><p><strong>K-Nearest Neighbors (KNN):</strong> Uses distance to classify a data point in the test set based upon the most common class of neighboring data points from the training set. For more information on KNN, see <a href="https://www.ibm.com/topics/knn">K-Nearest Neighbor</a>.
<img src="Module5_2_Input/Module5_2_Image6.png" width="50%" style="display: block; margin: auto;" /></p></li>
<li><p><strong>Support Vector Machine (SVM):</strong> Creates a decision boundary line (hyperplane) in n-dimensional space to separate the data into each class so that when new data is presented, they can be easily categorized. For more information on SVM, see <a href="https://www.javatpoint.com/machine-learning-support-vector-machine-algorithm">Support Vector Machine</a>.
<img src="Module5_2_Input/Module5_2_Image7.png" width="50%" style="display: block; margin: auto;" /></p></li>
<li><p><strong>Random Forest (RF):</strong> Uses a multitude of decision trees trained on a subset of different samples from the training set and the resulting classification of a data point in the test set is aggregated from all the decision trees. A <strong>decision tree</strong> is a hierarchical model that depicts decisions from predictors and their resulting outcomes. It starts with a root node, which represents an initial test from a single predictor. The root node splits into subsequent decision nodes that test another feature. These decision nodes can either feed into more decision nodes or leaf nodes that represent the predicted class label. A branch or a sub-tree refers to a subsection of an entire decision tree.</p></li>
</ul>
<p>Here is an example decision tree with potential variables and decisions informing a college basketball player’s likelihood of being drafted to the NBA:
<img src="Module5_2_Input/Module5_2_Image8.png" width="75%" style="display: block; margin: auto;" /></p>
<p>While decision trees are highly interpretable, they are prone to overfitting, thus they may not always generalize well to data outside of the training set. To address this, random forests are comprised of many different decision trees. Each tree is trained on a subset of the samples in the training data, selected with replacement, and a randomly selected set of predictor variables. For a dataset with <em>p</em> predictors, it is common to test <span class="math inline">\(\sqrt{p}\)</span>, <span class="math inline">\(\frac{p}{2}\)</span>, and <em>p</em> predictors to see which gives the best results. This process decorrelates the trees. For a classification problem, majority vote of the decision trees determines the final class for a prediction. This process loses interpretability inherent to individual trees, but reduces the risk of overfitting.</p>
<p>For more information on RF and decision trees, check out <a href="https://www.ibm.com/in-en/topics/random-forest">Random Forest</a> and
<a href="https://www.analyticsvidhya.com/blog/2021/08/decision-tree-algorithm/#What_is_a_Decision_Tree?">Decision Trees</a>.</p>
<p><strong>Note</strong>: One algorithm is not inherently better than the others with each having their respective advantages and disadvantages. Each algorithm’s predictive ability will be largely dependent on the size of the dataset, the distribution of the data points, and the scenario.</p>
<p><br></p>
</div>
<div id="training-supervised-machine-learning-models" class="section level2 hasAnchor">
<h2>Training Supervised Machine Learning Models<a href="supervised-machine-learning.html#training-supervised-machine-learning-models" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In supervised machine learning, algorithms need to be trained before they can be used to predict on new data. This involves selecting a smaller portion of the dataset to train the model so it will learn how to predict the outcome as accurately as possible. The process of training an algorithm is essential for enabling the model to learn and improve over time, allowing it to make more accurate predictions and better adapt to new and changing circumstances. Ultimately, the quality and relevance of the training data will have a significant impact on the effectiveness of a machine learning model.</p>
<p>Common partitions of the full dataset used to train and test a supervised machine learning model are the following:</p>
<ol style="list-style-type: decimal">
<li><p><strong>Training Set:</strong> a subset of the data that the algorithm “sees” and uses to identify patterns.</p></li>
<li><p><strong>Validation Set</strong>: a subset of the training set that is used to evaluate the model’s fit in an unbiased way allowing us to fine-tune its parameters and optimize performance.</p></li>
<li><p><strong>Test Set:</strong> a subset of data that is used to evaluate the final model’s fit based on the training and validation sets. This provides an objective assessment of the model’s ability to generalize new data.</p></li>
</ol>
<p>It is common to split the dataset into a training set that contains 60% of the data and the test set that contains 40% of the data, though other common splits include 70% training / 30% test and 80% training / 20% test.</p>
<p><img src="Module5_2_Input/Module5_2_Image3.png" width="65%" style="display: block; margin: auto;" /></p>
<p>It is important to note that the test set should only be examined after the algorithm has been trained using the training/validation sets. Using the test set during the development process can lead to overfitting, where the model performs well on the test data but poorly on new data. The ideal algorithm is generalizable or flexible enough to accurately predict unseen data. This is known as the bias-variance tradeoff. For further information on the bias-variance tradeoff, see <a href="https://towardsdatascience.com/understanding-the-bias-variance-tradeoff-165e6942b229">Understanding the Bias-Variance Tradeoff</a>.</p>
<div id="cross-validation" class="section level3 hasAnchor">
<h3>Cross Validation<a href="supervised-machine-learning.html#cross-validation" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Finally, we will discuss <strong>cross validation</strong>, which is an approach used during training to expose the model to more patterns in the data and aid in model evaluation. For example, if a model is trained and tested on a 60:40 split, our model’s accuracy will likely be influenced by <em>where</em> this 60:40 split occurs in the dataset. This will likely bias the data and reduce the algorithm’s ability to predict accurately for data not in the training set. Overall, cross validation (CV) is implemented to fine tune a model’s parameters and improve prediction accuracy and ability to generalize.</p>
<p>Although there are <a href="https://neptune.ai/blog/cross-validation-in-machine-learning-how-to-do-it-right">a number of cross validation approaches</a>, we will specifically highlight <strong><em>k</em>-fold cross validation</strong>. k-fold cross validation works by splitting the samples in the training dataset into <em>k</em> equally sized folds or groups. For example, if we implement 5-fold CV, we start by…</p>
<ol style="list-style-type: decimal">
<li>Splitting the training data into 5 groups, or “folds”.</li>
<li>Five iterations of training/testing are then run where each of the 5 folds serves as the test data once and as part of the training set four times, as seen in the figure below.</li>
<li>To measure predictive ability of each of the parameters tested, like the number of features to include, values like accuracy and specificity are calculated for each iteration. The parameters that optimize performance are selected for the final model which will be evaluated against the test set not used in training.
<img src="Module5_2_Input/Module5_2_Image4.png" width="1327" style="display: block; margin: auto;" /></li>
</ol>
<p>Check out these resources for additional information on <a href="https://towardsdatascience.com/cross-validation-in-machine-learning-72924a69872f">Cross Validation in Machine Learning</a> and <a href="https://www.geeksforgeeks.org/cross-validation-machine-learning/">Cross Validation Pros &amp; Cons</a>.</p>
<p><br></p>
</div>
</div>
<div id="assessing-classification-based-model-performance" class="section level2 hasAnchor">
<h2>Assessing Classification-Based Model Performance<a href="supervised-machine-learning.html#assessing-classification-based-model-performance" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Evaluation metrics from a confusion matrix are often used to determine the best model during training and measure model performance during testing for classification-based supervised machine learning models. A confusion matrix consists of a table that displays the numbers of how often the algorithm correctly and incorrectly predicted the outcome.</p>
<p>Let’s imagine you’re interested in predicting whether or not a player will be drafted to the National Basketball Association (NBA) based on a dataset that contains variables regarding a player’s assists, points, height etc. Let’s say that this dataset contains information on 253 players with 114 that were actually drafted and 139 that weren’t drafted. The confusion matrix below shows a model’s results where a player that is drafted is the “positive” class and a player that is not drafted is the “negative” class.</p>
<p><img src="Module5_2_Input/Module5_2_Image5.png" width="50%" style="display: block; margin: auto;" /></p>
<p>Helpful confusion matrix terminology:</p>
<ul>
<li><strong>True positive (TP)</strong>: the number of correctly classified “positive” data points (i.e., the number of correctly classified players to be drafted)</li>
<li><strong>True negative (TN)</strong>: the number of correctly classified “negative” data points (i.e., the number of correctly classified players to be not drafted)</li>
<li><strong>False positive (FP)</strong>: the number of incorrectly classified “positive” data points (i.e., the number of players not drafted incorrectly classified as draft picks)</li>
<li><strong>False negative (FN)</strong>: the number of incorrectly classified “negative” data points (i.e., the number of draft picks incorrectly classified as players not drafted)</li>
</ul>
<p>Some of the metrics that can be obtained from a confusion matrix are listed below:</p>
<ul>
<li><p><strong>Overall Accuracy:</strong> indicates how often the model makes a correct prediction relative to the total number of predictions made and is typically used to assess overall model performance (<span class="math inline">\(\frac{TP+TN}{TP+TN+FP+FN}\)</span>).</p></li>
<li><p><strong>Sensitivity or Recall:</strong> evaluates how well the model was able to predict the “positive” class. It is calculated as the ratio of correctly classified true positives to the total number of positive cases (<span class="math inline">\(\frac{TP}{TP+FN}\)</span>).</p></li>
<li><p><strong>Specificity:</strong> evaluates how well the model was able to predict the “negative” class. It is calculated as the ratio of correctly classified true negatives to total number of negatives cases (<span class="math inline">\(\frac{TN}{TN+FP}\)</span>).</p></li>
<li><p><strong>Balanced Accuracy:</strong> is the mean of sensitivity and specificity and is often used in the case of a class imbalance to gauge how well the model can correctly predict values for both classes (<span class="math inline">\(\frac{sensitivity+specificity}{2}\)</span>).</p></li>
<li><p><strong>Positive Predictive Value (PPV) or Precision:</strong> evaluates how accurate predictions of the “positive” class are. It is calculated as the ratio of correctly classified true positives to total number of predicted positives (<span class="math inline">\(\frac{TP}{TP+FN}\)</span>).</p></li>
<li><p><strong>Negative Predictive Value (NPV):</strong> evaluates how accurate predictions of the “negative” class are. It is calculated as the ratio of correctly classified true negatives to total number of predicted negatives (<span class="math inline">\(\frac{TN}{TN+FP}\)</span>).</p></li>
</ul>
<p>For the above metrics, values fall between 0 and 1. Instances of 0 indicate that the model was not able to classify any data points correctly, and instances of 1 indicate that the model was able to classify all test data correctly. Although subjective, an overall accuracy of at least 0.7 is considered respectable (<a href="https://www.obviously.ai/post/machine-learning-model-performance#:~:text=Good%20accuracy%20in%20machine%20learning,also%20consistent%20with%20industry%20standards.">Barkved, 2022</a>). Furthermore, a variety of additional metrics exist for evaluating model performance for classification problems (<a href="https://neptune.ai/blog/evaluation-metrics-binary-classification">24 Evaluation Metrics for Binary Classification (And When to Use Them)</a>). Selecting a metric for evaluating model performance varies by situation and is dependent not only on the individual dataset, but also the question being answered.</p>
<p><strong>Note</strong>: For multi-class classification (more than two labeled outcomes to be predicted), the same metrics are often used, but are obtained in a slightly different way. Regression based supervised machine learning models use loss functions to evaluate model performance. For more information regarding confusion matrices and loss functions for regression-based models, see:</p>
<ul>
<li><a href="https://medium.com/analytics-vidhya/what-is-a-confusion-matrix-d1c0f8feda5">Additional Confusion Matrix Metrics</a></li>
<li><a href="https://towardsdatascience.com/should-i-look-at-precision-recall-or-specificity-sensitivity-3946158aace1">Precision vs. Recall or Specificity vs. Sensitivity</a></li>
<li><a href="https://towardsdatascience.com/understanding-the-3-most-common-loss-functions-for-machine-learning-regression-23e0ef3e14d3">Loss Functions for Machine Learning Regression</a></li>
</ul>
<p><br></p>
</div>
<div id="introduction-to-activity-and-example-dataset" class="section level2 hasAnchor">
<h2>Introduction to Activity and Example Dataset<a href="supervised-machine-learning.html#introduction-to-activity-and-example-dataset" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In this activity, we will analyze an example dataset to see whether we can use environmental monitoring data to predict areas of contamination using random forest (RF). This example model will leverage a dataset of well water variables that span geospatial location, sampling date, and well water attributes, with the goal of predicting whether detectable levels of inorganic arsenic (iAs) are present. This dataset was obtained through the sampling of 713 private wells across North Carolina through the University of North Carolina Superfund Research Program (<a href="https://sph.unc.edu/superfund-pages/srp/">UNC-SRP</a>) using an analytical method that was capable of detecting levels of iAs greater than 5ppm. As demonstrated through the script below, the algorithm will first be trained and tested, and then resulting model performance will be assessed using the previously detailed confusion matrix and related performance metrics.</p>
<div id="training-modules-environmental-health-questions-10" class="section level3 hasAnchor">
<h3>Training Module’s Environmental Health Questions<a href="supervised-machine-learning.html#training-modules-environmental-health-questions-10" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>This training module was specifically developed to answer the following environmental health questions:</p>
<ol style="list-style-type: decimal">
<li>Which well water variables, spanning various geospatial locations, sampling dates, and well water attributes, significantly differ between samples containing detectable levels of iAs vs samples that are not contaminated/ non-detectable?</li>
<li>How can we train a random forest (RF) model to predict whether a well might be contaminated with iAs?</li>
<li>With this RF model, can we predict if iAs will be detected based on well water information?</li>
<li>How could this RF model be improved upon, acknowledging that there is class imbalance?</li>
</ol>
<p><br></p>
</div>
<div id="script-preparations-4" class="section level3 hasAnchor">
<h3>Script Preparations<a href="supervised-machine-learning.html#script-preparations-4" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="cleaning-the-global-environment-4" class="section level4 hasAnchor">
<h4>Cleaning the global environment<a href="supervised-machine-learning.html#cleaning-the-global-environment-4" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<div class="sourceCode" id="cb452"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb452-1"><a href="supervised-machine-learning.html#cb452-1" tabindex="-1"></a><span class="fu">rm</span>(<span class="at">list=</span><span class="fu">ls</span>())</span></code></pre></div>
</div>
<div id="installing-required-r-packages-4" class="section level4 hasAnchor">
<h4>Installing required R packages<a href="supervised-machine-learning.html#installing-required-r-packages-4" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>If you already have these packages installed, you can skip this step, or you can run the below code which checks installation status for you</p>
<div class="sourceCode" id="cb453"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb453-1"><a href="supervised-machine-learning.html#cb453-1" tabindex="-1"></a><span class="cf">if</span> (<span class="sc">!</span><span class="fu">requireNamespace</span>(<span class="st">&quot;readxl&quot;</span>))</span>
<span id="cb453-2"><a href="supervised-machine-learning.html#cb453-2" tabindex="-1"></a>  <span class="fu">install.packages</span>(<span class="st">&quot;readxl&quot;</span>);</span>
<span id="cb453-3"><a href="supervised-machine-learning.html#cb453-3" tabindex="-1"></a><span class="cf">if</span> (<span class="sc">!</span><span class="fu">requireNamespace</span>(<span class="st">&quot;lubridate&quot;</span>))</span>
<span id="cb453-4"><a href="supervised-machine-learning.html#cb453-4" tabindex="-1"></a>  <span class="fu">install.packages</span>(<span class="st">&quot;lubridate&quot;</span>);</span>
<span id="cb453-5"><a href="supervised-machine-learning.html#cb453-5" tabindex="-1"></a><span class="cf">if</span> (<span class="sc">!</span><span class="fu">requireNamespace</span>(<span class="st">&quot;tidyverse&quot;</span>))</span>
<span id="cb453-6"><a href="supervised-machine-learning.html#cb453-6" tabindex="-1"></a>  <span class="fu">install.packages</span>(<span class="st">&quot;tidyverse&quot;</span>);</span>
<span id="cb453-7"><a href="supervised-machine-learning.html#cb453-7" tabindex="-1"></a><span class="cf">if</span> (<span class="sc">!</span><span class="fu">requireNamespace</span>(<span class="st">&quot;gtsummary&quot;</span>))</span>
<span id="cb453-8"><a href="supervised-machine-learning.html#cb453-8" tabindex="-1"></a>  <span class="fu">install.packages</span>(<span class="st">&quot;gtsummary&quot;</span>);</span>
<span id="cb453-9"><a href="supervised-machine-learning.html#cb453-9" tabindex="-1"></a><span class="cf">if</span> (<span class="sc">!</span><span class="fu">requireNamespace</span>(<span class="st">&quot;flextable&quot;</span>))</span>
<span id="cb453-10"><a href="supervised-machine-learning.html#cb453-10" tabindex="-1"></a>  <span class="fu">install.packages</span>(<span class="st">&quot;flextable&quot;</span>);</span>
<span id="cb453-11"><a href="supervised-machine-learning.html#cb453-11" tabindex="-1"></a><span class="cf">if</span> (<span class="sc">!</span><span class="fu">requireNamespace</span>(<span class="st">&quot;caret&quot;</span>))</span>
<span id="cb453-12"><a href="supervised-machine-learning.html#cb453-12" tabindex="-1"></a>  <span class="fu">install.packages</span>(<span class="st">&quot;caret&quot;</span>);</span>
<span id="cb453-13"><a href="supervised-machine-learning.html#cb453-13" tabindex="-1"></a><span class="cf">if</span> (<span class="sc">!</span><span class="fu">requireNamespace</span>(<span class="st">&quot;randomForest&quot;</span>))</span>
<span id="cb453-14"><a href="supervised-machine-learning.html#cb453-14" tabindex="-1"></a>  <span class="fu">install.packages</span>(<span class="st">&quot;randomForest&quot;</span>);</span></code></pre></div>
</div>
<div id="loading-r-packages-required-for-this-session-3" class="section level4 hasAnchor">
<h4>Loading R packages required for this session<a href="supervised-machine-learning.html#loading-r-packages-required-for-this-session-3" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<div class="sourceCode" id="cb454"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb454-1"><a href="supervised-machine-learning.html#cb454-1" tabindex="-1"></a><span class="fu">library</span>(readxl);</span>
<span id="cb454-2"><a href="supervised-machine-learning.html#cb454-2" tabindex="-1"></a><span class="fu">library</span>(lubridate);</span>
<span id="cb454-3"><a href="supervised-machine-learning.html#cb454-3" tabindex="-1"></a><span class="fu">library</span>(tidyverse);</span>
<span id="cb454-4"><a href="supervised-machine-learning.html#cb454-4" tabindex="-1"></a><span class="fu">library</span>(gtsummary);</span>
<span id="cb454-5"><a href="supervised-machine-learning.html#cb454-5" tabindex="-1"></a><span class="fu">library</span>(flextable);</span>
<span id="cb454-6"><a href="supervised-machine-learning.html#cb454-6" tabindex="-1"></a><span class="fu">library</span>(caret);</span>
<span id="cb454-7"><a href="supervised-machine-learning.html#cb454-7" tabindex="-1"></a><span class="fu">library</span>(randomForest);</span></code></pre></div>
</div>
<div id="set-your-working-directory-5" class="section level4 hasAnchor">
<h4>Set your working directory<a href="supervised-machine-learning.html#set-your-working-directory-5" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<div class="sourceCode" id="cb455"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb455-1"><a href="supervised-machine-learning.html#cb455-1" tabindex="-1"></a><span class="fu">setwd</span>(<span class="st">&quot;/filepath to where your input files are&quot;</span>)</span></code></pre></div>
</div>
<div id="importing-example-dataset-4" class="section level4 hasAnchor">
<h4>Importing example dataset<a href="supervised-machine-learning.html#importing-example-dataset-4" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<div class="sourceCode" id="cb456"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb456-1"><a href="supervised-machine-learning.html#cb456-1" tabindex="-1"></a><span class="co"># Load the data</span></span>
<span id="cb456-2"><a href="supervised-machine-learning.html#cb456-2" tabindex="-1"></a>arsenic_data <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="fu">read_xlsx</span>(<span class="st">&quot;Module5_2_Input/Module5_2_InputData.xlsx&quot;</span>))</span>
<span id="cb456-3"><a href="supervised-machine-learning.html#cb456-3" tabindex="-1"></a></span>
<span id="cb456-4"><a href="supervised-machine-learning.html#cb456-4" tabindex="-1"></a><span class="co"># View the top of the dataset</span></span>
<span id="cb456-5"><a href="supervised-machine-learning.html#cb456-5" tabindex="-1"></a><span class="fu">head</span>(arsenic_data) </span></code></pre></div>
<pre><code>##   Well_ID Water_Sample_Date Casing_Depth Well_Depth Static_Water_Depth
## 1     W_1           9/24/12           52        165                 41
## 2     W_2          12/17/15           40        445                 42
## 3     W_3            2/2/15           45        160                 40
## 4     W_4          10/22/12           42        440                 57
## 5     W_5            1/3/11           48        120                 42
## 6     W_6          12/15/15           60        280                 32
##   Flow_Rate  pH Detect_Concentration
## 1      60.0 7.7                   ND
## 2       2.0 7.3                   ND
## 3      40.0 7.4                   ND
## 4       1.5 8.0                    D
## 5      25.0 7.1                   ND
## 6      10.0 8.2                    D</code></pre>
<p>The columns in this dataset are described below:</p>
<ul>
<li><code>Well_ID</code>: Unique id for each well (This is the sample identifier and not a predictive feature)</li>
<li><code>Water_Sample_Date</code>: Date that the well was sampled</li>
<li><code>Casing_Depth</code>: Depth of the casing of the well (ft)</li>
<li><code>Well_Depth</code>: Depth of the well (ft)</li>
<li><code>Static_Water_Depth</code>: Static water depth in the well (ft)</li>
<li><code>Flow_Rate</code>: Well flow rate (gallons per minute)</li>
<li><code>pH</code>: pH of water sample</li>
<li><code>Detect_Concentration</code>: Binary identifier (either non-detect “ND” or detect “D”) if iAs concentration detected in water sample</li>
</ul>
</div>
</div>
<div id="changing-data-types" class="section level3 hasAnchor">
<h3>Changing Data Types<a href="supervised-machine-learning.html#changing-data-types" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>First, <code>Detect_Concentration</code> needs to be converted from a character to a factor so that Random Forest knows that the non-detect class is the baseline or “negative” class, while the detect class will be the “positive” class. <code>Water_Sample_Date</code> will be converted from a character to a date type using the <code>mdy()</code> function from the <em>lubridate</em> package. This is done so that the model understands this column contains dates.</p>
<div class="sourceCode" id="cb458"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb458-1"><a href="supervised-machine-learning.html#cb458-1" tabindex="-1"></a>arsenic_data <span class="ot">&lt;-</span> arsenic_data <span class="sc">%&gt;%</span></span>
<span id="cb458-2"><a href="supervised-machine-learning.html#cb458-2" tabindex="-1"></a>    <span class="co"># Converting `Detect_Concentration` from a character to a factor</span></span>
<span id="cb458-3"><a href="supervised-machine-learning.html#cb458-3" tabindex="-1"></a>    <span class="fu">mutate</span>(<span class="at">Detect_Concentration =</span> <span class="fu">relevel</span>(<span class="fu">factor</span>(Detect_Concentration), <span class="at">ref =</span> <span class="st">&quot;ND&quot;</span>), </span>
<span id="cb458-4"><a href="supervised-machine-learning.html#cb458-4" tabindex="-1"></a>    <span class="co"># Converting water sample date from a character to a date type </span></span>
<span id="cb458-5"><a href="supervised-machine-learning.html#cb458-5" tabindex="-1"></a>    <span class="at">Water_Sample_Date =</span> <span class="fu">mdy</span>(Water_Sample_Date)) <span class="sc">%&gt;%</span> </span>
<span id="cb458-6"><a href="supervised-machine-learning.html#cb458-6" tabindex="-1"></a>    <span class="co"># Removing tax id and only keeping the predictor and outcome variables in the dataset</span></span>
<span id="cb458-7"><a href="supervised-machine-learning.html#cb458-7" tabindex="-1"></a>    <span class="co"># This allows us to put the entire dataframe as is into RF</span></span>
<span id="cb458-8"><a href="supervised-machine-learning.html#cb458-8" tabindex="-1"></a>    <span class="fu">select</span>(<span class="sc">-</span>Well_ID) </span>
<span id="cb458-9"><a href="supervised-machine-learning.html#cb458-9" tabindex="-1"></a></span>
<span id="cb458-10"><a href="supervised-machine-learning.html#cb458-10" tabindex="-1"></a><span class="co"># Look at the top of the revised dataset</span></span>
<span id="cb458-11"><a href="supervised-machine-learning.html#cb458-11" tabindex="-1"></a><span class="fu">head</span>(arsenic_data)</span></code></pre></div>
<pre><code>##   Water_Sample_Date Casing_Depth Well_Depth Static_Water_Depth Flow_Rate  pH
## 1        2012-09-24           52        165                 41      60.0 7.7
## 2        2015-12-17           40        445                 42       2.0 7.3
## 3        2015-02-02           45        160                 40      40.0 7.4
## 4        2012-10-22           42        440                 57       1.5 8.0
## 5        2011-01-03           48        120                 42      25.0 7.1
## 6        2015-12-15           60        280                 32      10.0 8.2
##   Detect_Concentration
## 1                   ND
## 2                   ND
## 3                   ND
## 4                    D
## 5                   ND
## 6                    D</code></pre>
<p><br></p>
</div>
</div>
<div id="testing-for-differences-in-predictor-variables-across-the-outcome-classes" class="section level2 hasAnchor">
<h2>Testing for Differences in Predictor Variables across the Outcome Classes<a href="supervised-machine-learning.html#testing-for-differences-in-predictor-variables-across-the-outcome-classes" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>It is useful to run summary statistics on the variables that will be used as predictors in the algorithm to see if there are differences in distributions between the outcomes classes (either non-detect or detect in this case). Typically, greater significance often leads to better predictivity for a certain variable, since the model is better able to separate the classes. We’ll use the <code>tbl_summary()</code> function from the <em>gtsummary</em> package. Note, this may only be practical with smaller datasets or for a subset of predictors if there are many.</p>
<p>For more information on the <code>tbl_summary()</code> function, check out this helpful <a href="https://www.danieldsjoberg.com/gtsummary/articles/tbl_summary.html">Tutorial</a>.</p>
<div class="sourceCode" id="cb460"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb460-1"><a href="supervised-machine-learning.html#cb460-1" tabindex="-1"></a>arsenic_data <span class="sc">%&gt;%</span></span>
<span id="cb460-2"><a href="supervised-machine-learning.html#cb460-2" tabindex="-1"></a>    <span class="co"># Displaying the mean and standard deviation in parentheses for all continuous variables</span></span>
<span id="cb460-3"><a href="supervised-machine-learning.html#cb460-3" tabindex="-1"></a>    <span class="fu">tbl_summary</span>(<span class="at">by =</span> Detect_Concentration, <span class="at">statistic =</span> <span class="fu">list</span>(<span class="fu">all_continuous</span>() <span class="sc">~</span> <span class="st">&quot;{mean} ({sd})&quot;</span>)) <span class="sc">%&gt;%</span> </span>
<span id="cb460-4"><a href="supervised-machine-learning.html#cb460-4" tabindex="-1"></a>    <span class="co"># Adding a column that displays the total number of samples for each variable. This will be 713 for all variables since we have no missing data</span></span>
<span id="cb460-5"><a href="supervised-machine-learning.html#cb460-5" tabindex="-1"></a>    <span class="fu">add_n</span>() <span class="sc">%&gt;%</span>     </span>
<span id="cb460-6"><a href="supervised-machine-learning.html#cb460-6" tabindex="-1"></a>    <span class="co"># Adding a column that displays the p-value from an anova test</span></span>
<span id="cb460-7"><a href="supervised-machine-learning.html#cb460-7" tabindex="-1"></a>    <span class="fu">add_p</span>(<span class="at">test =</span> <span class="fu">list</span>(<span class="fu">all_continuous</span>() <span class="sc">~</span> <span class="st">&quot;aov&quot;</span>)) <span class="sc">%&gt;%</span> </span>
<span id="cb460-8"><a href="supervised-machine-learning.html#cb460-8" tabindex="-1"></a>    <span class="fu">as_flex_table</span>() <span class="sc">%&gt;%</span></span>
<span id="cb460-9"><a href="supervised-machine-learning.html#cb460-9" tabindex="-1"></a>    <span class="fu">bold</span>(<span class="at">bold =</span> <span class="cn">TRUE</span>, <span class="at">part =</span> <span class="st">&quot;header&quot;</span>)</span></code></pre></div>
<pre><code>## The following errors were returned during `as_flex_table()`:
## ✖ For variable `Casing_Depth` (`Detect_Concentration`) and &quot;p.value&quot;
##   statistic: The package &quot;cardx&quot; (&gt;= 0.2.1) is required.
## ✖ For variable `Flow_Rate` (`Detect_Concentration`) and &quot;p.value&quot;
##   statistic: The package &quot;cardx&quot; (&gt;= 0.2.1) is required.
## ✖ For variable `Static_Water_Depth` (`Detect_Concentration`) and
##   &quot;p.value&quot; statistic: The package &quot;cardx&quot; (&gt;= 0.2.1) is required.
## ✖ For variable `Water_Sample_Date` (`Detect_Concentration`) and
##   &quot;p.value&quot; statistic: The package &quot;cardx&quot; (&gt;= 0.2.1) is required.
## ✖ For variable `Well_Depth` (`Detect_Concentration`) and &quot;p.value&quot;
##   statistic: The package &quot;cardx&quot; (&gt;= 0.2.1) is required.
## ✖ For variable `pH` (`Detect_Concentration`) and &quot;p.value&quot; statistic:
##   The package &quot;cardx&quot; (&gt;= 0.2.1) is required.</code></pre>
<div class="tabwid"><style>.cl-0244e6de{}.cl-023f84c8{font-family:'Arial';font-size:11pt;font-weight:bold;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-023f84d2{font-family:'Arial';font-size:6.6pt;font-weight:bold;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;position: relative;bottom:3.3pt;}.cl-023f84dc{font-family:'Arial';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-023f84dd{font-family:'Arial';font-size:6.6pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;position: relative;bottom:3.3pt;}.cl-02418cfa{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:2pt;padding-top:2pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-02418cfb{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:2pt;padding-top:2pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-02418d04{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-02418d05{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-02418d06{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-0241a1b8{width:1.703in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-0241a1b9{width:0.54in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-0241a1c2{width:2.528in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-0241a1c3{width:0.82in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-0241a1cc{width:1.703in;background-color:transparent;vertical-align: top;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-0241a1cd{width:0.54in;background-color:transparent;vertical-align: top;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-0241a1ce{width:2.528in;background-color:transparent;vertical-align: top;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-0241a1cf{width:0.82in;background-color:transparent;vertical-align: top;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-0241a1d6{width:1.703in;background-color:transparent;vertical-align: top;border-bottom: 1pt solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-0241a1d7{width:0.54in;background-color:transparent;vertical-align: top;border-bottom: 1pt solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-0241a1d8{width:2.528in;background-color:transparent;vertical-align: top;border-bottom: 1pt solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-0241a1d9{width:0.82in;background-color:transparent;vertical-align: top;border-bottom: 1pt solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-0241a1da{width:1.703in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(255, 255, 255, 0.00);border-top: 0 solid rgba(255, 255, 255, 0.00);border-left: 0 solid rgba(255, 255, 255, 0.00);border-right: 0 solid rgba(255, 255, 255, 0.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-0241a1e0{width:0.54in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(255, 255, 255, 0.00);border-top: 0 solid rgba(255, 255, 255, 0.00);border-left: 0 solid rgba(255, 255, 255, 0.00);border-right: 0 solid rgba(255, 255, 255, 0.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-0241a1e1{width:2.528in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(255, 255, 255, 0.00);border-top: 0 solid rgba(255, 255, 255, 0.00);border-left: 0 solid rgba(255, 255, 255, 0.00);border-right: 0 solid rgba(255, 255, 255, 0.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-0241a1e2{width:0.82in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(255, 255, 255, 0.00);border-top: 0 solid rgba(255, 255, 255, 0.00);border-left: 0 solid rgba(255, 255, 255, 0.00);border-right: 0 solid rgba(255, 255, 255, 0.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table data-quarto-disable-processing='true' class='cl-0244e6de'><thead><tr style="overflow-wrap:break-word;"><th class="cl-0241a1b8"><p class="cl-02418cfa"><span class="cl-023f84c8">Characteristic</span></p></th><th class="cl-0241a1b9"><p class="cl-02418cfb"><span class="cl-023f84c8">N</span></p></th><th class="cl-0241a1c2"><p class="cl-02418cfb"><span class="cl-023f84c8">ND</span><span class="cl-023f84c8">  </span><br><span class="cl-023f84c8">N = 515</span><span class="cl-023f84d2">1</span></p></th><th class="cl-0241a1c2"><p class="cl-02418cfb"><span class="cl-023f84c8">D</span><span class="cl-023f84c8">  </span><br><span class="cl-023f84c8">N = 198</span><span class="cl-023f84d2">1</span></p></th><th class="cl-0241a1c3"><p class="cl-02418cfb"><span class="cl-023f84c8">p-value</span></p></th></tr></thead><tbody><tr style="overflow-wrap:break-word;"><td class="cl-0241a1cc"><p class="cl-02418d04"><span class="cl-023f84dc">Water_Sample_Date</span></p></td><td class="cl-0241a1cd"><p class="cl-02418d05"><span class="cl-023f84dc">713</span></p></td><td class="cl-0241a1ce"><p class="cl-02418d05"><span class="cl-023f84dc">2013-06-05 (979.174260670888)</span></p></td><td class="cl-0241a1ce"><p class="cl-02418d05"><span class="cl-023f84dc">2013-03-05 (957.843005291701)</span></p></td><td class="cl-0241a1cf"><p class="cl-02418d05"><span class="cl-023f84dc"></span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-0241a1cc"><p class="cl-02418d04"><span class="cl-023f84dc">Casing_Depth</span></p></td><td class="cl-0241a1cd"><p class="cl-02418d05"><span class="cl-023f84dc">713</span></p></td><td class="cl-0241a1ce"><p class="cl-02418d05"><span class="cl-023f84dc">74 (33)</span></p></td><td class="cl-0241a1ce"><p class="cl-02418d05"><span class="cl-023f84dc">55 (23)</span></p></td><td class="cl-0241a1cf"><p class="cl-02418d05"><span class="cl-023f84dc"></span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-0241a1cc"><p class="cl-02418d04"><span class="cl-023f84dc">Well_Depth</span></p></td><td class="cl-0241a1cd"><p class="cl-02418d05"><span class="cl-023f84dc">713</span></p></td><td class="cl-0241a1ce"><p class="cl-02418d05"><span class="cl-023f84dc">301 (144)</span></p></td><td class="cl-0241a1ce"><p class="cl-02418d05"><span class="cl-023f84dc">334 (128)</span></p></td><td class="cl-0241a1cf"><p class="cl-02418d05"><span class="cl-023f84dc"></span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-0241a1cc"><p class="cl-02418d04"><span class="cl-023f84dc">Static_Water_Depth</span></p></td><td class="cl-0241a1cd"><p class="cl-02418d05"><span class="cl-023f84dc">713</span></p></td><td class="cl-0241a1ce"><p class="cl-02418d05"><span class="cl-023f84dc">35 (12)</span></p></td><td class="cl-0241a1ce"><p class="cl-02418d05"><span class="cl-023f84dc">36 (13)</span></p></td><td class="cl-0241a1cf"><p class="cl-02418d05"><span class="cl-023f84dc"></span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-0241a1cc"><p class="cl-02418d04"><span class="cl-023f84dc">Flow_Rate</span></p></td><td class="cl-0241a1cd"><p class="cl-02418d05"><span class="cl-023f84dc">713</span></p></td><td class="cl-0241a1ce"><p class="cl-02418d05"><span class="cl-023f84dc">25 (33)</span></p></td><td class="cl-0241a1ce"><p class="cl-02418d05"><span class="cl-023f84dc">14 (16)</span></p></td><td class="cl-0241a1cf"><p class="cl-02418d05"><span class="cl-023f84dc"></span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-0241a1d6"><p class="cl-02418d04"><span class="cl-023f84dc">pH</span></p></td><td class="cl-0241a1d7"><p class="cl-02418d05"><span class="cl-023f84dc">713</span></p></td><td class="cl-0241a1d8"><p class="cl-02418d05"><span class="cl-023f84dc">7.45 (0.55)</span></p></td><td class="cl-0241a1d8"><p class="cl-02418d05"><span class="cl-023f84dc">7.82 (0.40)</span></p></td><td class="cl-0241a1d9"><p class="cl-02418d05"><span class="cl-023f84dc"></span></p></td></tr></tbody><tfoot><tr style="overflow-wrap:break-word;"><td  colspan="5"class="cl-0241a1da"><p class="cl-02418d06"><span class="cl-023f84dd">1</span><span class="cl-023f84dc">Mean (SD)</span></p></td></tr></tfoot></table></div>
<p>Note that N refers to the total sample number; ND refers to the samples that contained non-detectable levels of iAs; and D refers to the samples that contained detectable levels of iAs.</p>
<div id="answer-to-environmental-health-question-1-6" class="section level3 hasAnchor">
<h3>Answer to Environmental Health Question 1<a href="supervised-machine-learning.html#answer-to-environmental-health-question-1-6" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="question">
<p><em>With this, we can answer <strong>Environmental Health Question #1</strong></em>: Which well water variables, spanning various geospatial locations, sampling dates, and well water attributes, significantly differ between samples containing detectable levels of iAs vs samples that are not contaminated/ non-detect?</p>
</div>
<div class="answer">
<p><strong>Answer</strong>: All of the evaluated descriptor variables are significantly different, with p&lt;0.05 between detect and non-detect iAs samples, with the exception of the sample date and the static water depth.</p>
</div>
<p>With these findings, we feel comfortable moving forward with these well water descriptive variables as predictors in our model.</p>
<p><br></p>
</div>
<div id="setting-up-cross-validation" class="section level3 hasAnchor">
<h3>Setting up Cross Validation<a href="supervised-machine-learning.html#setting-up-cross-validation" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>At this point, we can move forward with training and testing a RF model aimed at predicting whether or not detectable levels of iAs are present in well water samples. We’ll take a glance at the distribution of <code>Detect_Concentration</code> between the two classes.</p>
<div class="sourceCode" id="cb462"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb462-1"><a href="supervised-machine-learning.html#cb462-1" tabindex="-1"></a><span class="co"># Set seed for reproducibility</span></span>
<span id="cb462-2"><a href="supervised-machine-learning.html#cb462-2" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">17</span>)</span>
<span id="cb462-3"><a href="supervised-machine-learning.html#cb462-3" tabindex="-1"></a></span>
<span id="cb462-4"><a href="supervised-machine-learning.html#cb462-4" tabindex="-1"></a><span class="co"># Establish a list of indices that will used to identify our training and testing data with a 60-40 split</span></span>
<span id="cb462-5"><a href="supervised-machine-learning.html#cb462-5" tabindex="-1"></a>tt_indices <span class="ot">&lt;-</span> <span class="fu">createDataPartition</span>(<span class="at">y =</span> arsenic_data<span class="sc">$</span>Detect_Concentration, <span class="at">p =</span> <span class="fl">0.6</span>, <span class="at">list =</span> <span class="cn">FALSE</span>)</span>
<span id="cb462-6"><a href="supervised-machine-learning.html#cb462-6" tabindex="-1"></a></span>
<span id="cb462-7"><a href="supervised-machine-learning.html#cb462-7" tabindex="-1"></a><span class="co"># Use indices to make our training and testing datasets and view the number of Ds and NDs</span></span>
<span id="cb462-8"><a href="supervised-machine-learning.html#cb462-8" tabindex="-1"></a>iAs_train <span class="ot">&lt;-</span> arsenic_data[tt_indices,]</span>
<span id="cb462-9"><a href="supervised-machine-learning.html#cb462-9" tabindex="-1"></a><span class="fu">table</span>(iAs_train<span class="sc">$</span>Detect_Concentration)</span></code></pre></div>
<pre><code>## 
##  ND   D 
## 309 119</code></pre>
<div class="sourceCode" id="cb464"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb464-1"><a href="supervised-machine-learning.html#cb464-1" tabindex="-1"></a>iAs_test <span class="ot">&lt;-</span> arsenic_data[<span class="sc">-</span>tt_indices,]</span>
<span id="cb464-2"><a href="supervised-machine-learning.html#cb464-2" tabindex="-1"></a><span class="fu">table</span>(iAs_test<span class="sc">$</span>Detect_Concentration)</span></code></pre></div>
<pre><code>## 
##  ND   D 
## 206  79</code></pre>
<p>We can see that there are notably more non-detects (<code>ND</code>) than detects (<code>D</code>) in both our training and testing sets. This is something important to consider when evaluating our model’s performance.</p>
<p>Now we can set up our cross validation and train our model. We will be using the <code>trainControl()</code> function from the <em>caret</em> package for this task. It is one of the most commonly used libraries for supervised machine learning in R and can be leveraged for a variety algorithms including RF, SVM, KNN, and others. This model will be trained with 5-fold cross validation. Additionally, we will test 2, 3, and 6 predictors through the <code>mtry</code> parameter.</p>
<p>See the <em>caret</em> documentation <a href="https://cran.r-project.org/web/packages/caret/vignettes/caret.html">here</a>.</p>
<div class="sourceCode" id="cb466"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb466-1"><a href="supervised-machine-learning.html#cb466-1" tabindex="-1"></a><span class="co"># Establish the parameters for our cross validation with 5 folds</span></span>
<span id="cb466-2"><a href="supervised-machine-learning.html#cb466-2" tabindex="-1"></a>control <span class="ot">&lt;-</span> <span class="fu">trainControl</span>(<span class="at">method =</span> <span class="st">&#39;cv&#39;</span>,</span>
<span id="cb466-3"><a href="supervised-machine-learning.html#cb466-3" tabindex="-1"></a>                        <span class="at">number =</span> <span class="dv">5</span>,</span>
<span id="cb466-4"><a href="supervised-machine-learning.html#cb466-4" tabindex="-1"></a>                        <span class="at">search =</span> <span class="st">&#39;grid&#39;</span>,</span>
<span id="cb466-5"><a href="supervised-machine-learning.html#cb466-5" tabindex="-1"></a>                        <span class="at">classProbs =</span> <span class="cn">TRUE</span>)</span>
<span id="cb466-6"><a href="supervised-machine-learning.html#cb466-6" tabindex="-1"></a></span>
<span id="cb466-7"><a href="supervised-machine-learning.html#cb466-7" tabindex="-1"></a><span class="co"># Establish grid of predictors to test in our model as part of hyperparameter tuning</span></span>
<span id="cb466-8"><a href="supervised-machine-learning.html#cb466-8" tabindex="-1"></a>p <span class="ot">&lt;-</span> <span class="fu">ncol</span>(arsenic_data) <span class="sc">-</span> <span class="dv">1</span> <span class="co"># p is the total number of predictors in the dataset</span></span>
<span id="cb466-9"><a href="supervised-machine-learning.html#cb466-9" tabindex="-1"></a>tunegrid_rf <span class="ot">&lt;-</span> <span class="fu">expand.grid</span>(<span class="at">mtry =</span> <span class="fu">c</span>(<span class="fu">floor</span>(<span class="fu">sqrt</span>(p)), p<span class="sc">/</span><span class="dv">2</span>, p)) <span class="co"># We will test sqrt(p), p/2, and p predictors (2,3,&amp; 6 predictors, respectively) to see which performs best</span></span></code></pre></div>
<p><br></p>
</div>
</div>
<div id="predicting-ias-detection-with-a-random-forest-rf-model" class="section level2 hasAnchor">
<h2>Predicting iAs Detection with a Random Forest (RF) Model<a href="supervised-machine-learning.html#predicting-ias-detection-with-a-random-forest-rf-model" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div class="sourceCode" id="cb467"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb467-1"><a href="supervised-machine-learning.html#cb467-1" tabindex="-1"></a><span class="co"># Look at the column names in training dataset</span></span>
<span id="cb467-2"><a href="supervised-machine-learning.html#cb467-2" tabindex="-1"></a><span class="fu">colnames</span>(iAs_train)</span></code></pre></div>
<pre><code>## [1] &quot;Water_Sample_Date&quot;    &quot;Casing_Depth&quot;         &quot;Well_Depth&quot;          
## [4] &quot;Static_Water_Depth&quot;   &quot;Flow_Rate&quot;            &quot;pH&quot;                  
## [7] &quot;Detect_Concentration&quot;</code></pre>
<div class="sourceCode" id="cb469"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb469-1"><a href="supervised-machine-learning.html#cb469-1" tabindex="-1"></a><span class="co"># Train model</span></span>
<span id="cb469-2"><a href="supervised-machine-learning.html#cb469-2" tabindex="-1"></a>rf_train <span class="ot">&lt;-</span> <span class="fu">train</span>(<span class="at">x =</span> iAs_train[,<span class="dv">1</span><span class="sc">:</span><span class="dv">6</span>], <span class="co"># Our predictor variables are in columns 1-6 of the dataframe</span></span>
<span id="cb469-3"><a href="supervised-machine-learning.html#cb469-3" tabindex="-1"></a>                         <span class="at">y =</span> iAs_train[,<span class="dv">7</span>], <span class="co"># Our outcome variable is in column 7 of the dataframe</span></span>
<span id="cb469-4"><a href="supervised-machine-learning.html#cb469-4" tabindex="-1"></a>                         <span class="at">trControl =</span> control, <span class="co"># Specify the cross-validation parameters we defined above</span></span>
<span id="cb469-5"><a href="supervised-machine-learning.html#cb469-5" tabindex="-1"></a>                         <span class="at">method =</span> <span class="st">&#39;rf&#39;</span>, <span class="co"># Specify we want to train a Random Forest</span></span>
<span id="cb469-6"><a href="supervised-machine-learning.html#cb469-6" tabindex="-1"></a>                         <span class="at">importance =</span> <span class="cn">TRUE</span>, <span class="co"># This parameter calculates the variable importance for RF models specifically which can help with downstream analyses</span></span>
<span id="cb469-7"><a href="supervised-machine-learning.html#cb469-7" tabindex="-1"></a>                         <span class="at">tuneGrid =</span> tunegrid_rf, <span class="co"># Specify the number of predictors we want to test as defined above</span></span>
<span id="cb469-8"><a href="supervised-machine-learning.html#cb469-8" tabindex="-1"></a>                         <span class="at">metric =</span> <span class="st">&quot;Accuracy&quot;</span>,</span>
<span id="cb469-9"><a href="supervised-machine-learning.html#cb469-9" tabindex="-1"></a>                  ) <span class="co"># Specify what evaluation metric we want to use to decide which model is the best</span></span>
<span id="cb469-10"><a href="supervised-machine-learning.html#cb469-10" tabindex="-1"></a></span>
<span id="cb469-11"><a href="supervised-machine-learning.html#cb469-11" tabindex="-1"></a><span class="co"># Look at the results of training</span></span>
<span id="cb469-12"><a href="supervised-machine-learning.html#cb469-12" tabindex="-1"></a>rf_train</span></code></pre></div>
<pre><code>## Random Forest 
## 
## 428 samples
##   6 predictor
##   2 classes: &#39;ND&#39;, &#39;D&#39; 
## 
## No pre-processing
## Resampling: Cross-Validated (5 fold) 
## Summary of sample sizes: 344, 342, 342, 342, 342 
## Resampling results across tuning parameters:
## 
##   mtry  Accuracy   Kappa    
##   2     0.7548726  0.3329518
##   3     0.7361019  0.2891243
##   6     0.7501661  0.3257679
## 
## Accuracy was used to select the optimal model using the largest value.
## The final value used for the model was mtry = 2.</code></pre>
<div class="sourceCode" id="cb471"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb471-1"><a href="supervised-machine-learning.html#cb471-1" tabindex="-1"></a><span class="co"># Save the best model from our training. The best performing model is determined by the number of predictor variables we tested that resulted in the highest accuracy during the cross validation step.</span></span>
<span id="cb471-2"><a href="supervised-machine-learning.html#cb471-2" tabindex="-1"></a>rf_final <span class="ot">&lt;-</span> rf_train<span class="sc">$</span>finalModel</span>
<span id="cb471-3"><a href="supervised-machine-learning.html#cb471-3" tabindex="-1"></a></span>
<span id="cb471-4"><a href="supervised-machine-learning.html#cb471-4" tabindex="-1"></a><span class="co"># View confusion matrix for best model</span></span>
<span id="cb471-5"><a href="supervised-machine-learning.html#cb471-5" tabindex="-1"></a>rf_final</span></code></pre></div>
<pre><code>## 
## Call:
##  randomForest(x = x, y = y, mtry = param$mtry, importance = TRUE) 
##                Type of random forest: classification
##                      Number of trees: 500
## No. of variables tried at each split: 2
## 
##         OOB estimate of  error rate: 24.77%
## Confusion matrix:
##     ND  D class.error
## ND 275 34   0.1100324
## D   72 47   0.6050420</code></pre>
<div id="answer-to-environmental-health-question-2-7" class="section level3 hasAnchor">
<h3>Answer to Environmental Health Question 2<a href="supervised-machine-learning.html#answer-to-environmental-health-question-2-7" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="question">
<p><em>With this, we can answer <strong>Environmental Health Question #2</strong></em>: How can we train a random forest (RF) model to predict whether a well might be contaminated with iAs?</p>
</div>
<div class="answer">
<p><strong>Answer</strong>: As is standard practice with supervised ML, we split our full dataset into a training dataset and a test dataset using a 60-40 split. Using the <em>caret</em> package, we implemented 5-fold cross validation to train a RF while also testing different numbers of predictors to see which optimized performance. The model that resulted in the greatest accuracy was selected as the final model.</p>
</div>
<p>Now we can see how well our model does on data it hasn’t seen before by applying it to our testing data.</p>
<div class="sourceCode" id="cb473"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb473-1"><a href="supervised-machine-learning.html#cb473-1" tabindex="-1"></a><span class="co"># Use our best model to predict the classes for our test data. We need to make sure we remove the column of Ds/NDs from our test data.</span></span>
<span id="cb473-2"><a href="supervised-machine-learning.html#cb473-2" tabindex="-1"></a>rf_res <span class="ot">&lt;-</span> <span class="fu">predict</span>(rf_final, iAs_test <span class="sc">%&gt;%</span> </span>
<span id="cb473-3"><a href="supervised-machine-learning.html#cb473-3" tabindex="-1"></a>                    <span class="fu">select</span>(<span class="sc">!</span>Detect_Concentration))</span>
<span id="cb473-4"><a href="supervised-machine-learning.html#cb473-4" tabindex="-1"></a></span>
<span id="cb473-5"><a href="supervised-machine-learning.html#cb473-5" tabindex="-1"></a><span class="co"># View a confusion matrix of the results and gauge model performance</span></span>
<span id="cb473-6"><a href="supervised-machine-learning.html#cb473-6" tabindex="-1"></a><span class="co"># Be sure to include the &#39;positive&#39; parameter to specify the correct positive class</span></span>
<span id="cb473-7"><a href="supervised-machine-learning.html#cb473-7" tabindex="-1"></a><span class="fu">confusionMatrix</span>(rf_res, iAs_test<span class="sc">$</span>Detect_Concentration, <span class="at">positive =</span> <span class="st">&quot;D&quot;</span>)</span></code></pre></div>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction  ND   D
##         ND 178  47
##         D   28  32
##                                          
##                Accuracy : 0.7368         
##                  95% CI : (0.6817, 0.787)
##     No Information Rate : 0.7228         
##     P-Value [Acc &gt; NIR] : 0.32445        
##                                          
##                   Kappa : 0.2907         
##                                          
##  Mcnemar&#39;s Test P-Value : 0.03767        
##                                          
##             Sensitivity : 0.4051         
##             Specificity : 0.8641         
##          Pos Pred Value : 0.5333         
##          Neg Pred Value : 0.7911         
##              Prevalence : 0.2772         
##          Detection Rate : 0.1123         
##    Detection Prevalence : 0.2105         
##       Balanced Accuracy : 0.6346         
##                                          
##        &#39;Positive&#39; Class : D              
## </code></pre>
</div>
<div id="answer-to-environmental-health-question-3-3" class="section level3 hasAnchor">
<h3>Answer to Environmental Health Question 3<a href="supervised-machine-learning.html#answer-to-environmental-health-question-3-3" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="question">
<p><em>With this, we can answer <strong>Environmental Health Question #3</strong></em>: With this RF model, can we predict if iAs will be detected based on well water information?</p>
</div>
<div class="answer">
<p><strong>Answer</strong>: We can use this model to predict if iAs can be detected in well water given that an overall accuracy of ~0.72 is decent, however we should consider other metrics that may influence how good we feel about this model depending on what is important to the question we are trying to answer. For example, the model did a good job at predicting non-detect data based on a sensitivity of ~0.85 and a NPV ~0.78, but struggled at predicting detect data based on a specificity of ~0.39 and a PPV of ~0.50. Additionally, the balanced accuracy of ~0.62 further emphasizes the difference in predictive ability of the model for non-detects and detects. If it is highly important to us that detects are classified correctly, we may want to improve this model before implementing it.</p>
</div>
<p><br></p>
</div>
</div>
<div id="class-imbalance" class="section level2 hasAnchor">
<h2>Class Imbalance<a href="supervised-machine-learning.html#class-imbalance" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>It is worth noting this discrepancy in predictive capabilities for detects vs. non-detects makes sense due to the observed class imbalance in our training data. There were notably more non-detects than detects in the training set, so the model was exposed to more of these data points and struggles to distinguish unique characteristics of detects when compared to non-detects. Additionally, we told the training algorithm to prioritize selecting a final model based on its overall accuracy. In the instances of a heavy class imbalance, it is common for a high accuracy to be achieved as the more prevalent class is predicted more often, though this doesn’t give the full picture of the model’s predictive capabilities. For example, if you consider a dog/cat case with a set of 90 dogs and 10 cats, a model could achieve 90% accuracy by predicting dog every time, which isn’t at all helpful in predicting cats.</p>
<p>This is particularly important, because for toxicology related datasets, the “positive” class often represents the class with greater public health risk/ interest but can have less data. For example, when you classify subjects based upon whether or not they have asthma based on gene expression data. Asthmatics would likely be the “positive” class, but given that asthmatics are less prevalent than non-asthmatics in the general population, they would likely represent the minority class too.</p>
<p>To address this issue, a few methods can be considered. Full implementation of these approaches is beyond the scope of this module, but relevant resources for further exploration are given.</p>
<ul>
<li><p><strong>Synthetic Minority Oversampling Technique (SMOTE)</strong>- increases the number of minority classes in the training data, thereby reducing the class imbalance by synthetically generating additional samples derived from the existing minority class samples.</p>
<ul>
<li><a href="https://spotintelligence.com/2023/02/17/smote-oversampling-python-r/#:~:text=Conclusion-,The%20SMOTE%20(Synthetic%20Minority%20Over%2Dsampling%20Technique)%20algorithm%20is,datasets%20that%20aren&#39;t%20balanced.">SMOTE Oversampling &amp; Tutorial On How To Implement In Python And R</a></li>
<li><a href="https://www.statology.org/smote-in-r/">How to Use SMOTE for Imbalanced Data in R (With Example)</a></li>
</ul></li>
<li><p><strong>Adjusting the loss function</strong>- Loss functions in machine learning quantify the penalty for a bad prediction. They can be adjusted to where the minority class is penalized more forcing the model to learn to make fewer mistakes when predicting the minority class.</p></li>
<li><p><strong>Alternative Performance Metrics</strong>- When training the model, alternative metrics to overall accuracy may yield a more robust model capable of better predicting the minority class. Example alternatives may include balanced accuracy or an <a href="https://thedatascientist.com/f-1-measure-useful-imbalanced-class-problems/">F1-score</a>. The <em>caret</em> package further allows for <a href="https://topepo.github.io/caret/model-training-and-tuning.html#alternate-performance-metrics">custom, user-defined metrics</a> to be evaluated during training by specifying the <em>summaryFunction</em> parameter in the <code>trainControl()</code> function, as seen below, in addition to the <a href="https://cran.r-project.org/web/packages/caret/vignettes/caret.html"><code>defaultSummary()</code> and <code>twoClassSummary()</code> functions</a>.</p></li>
</ul>
<p>In the example code below, we’re creating a function (<code>f1</code>) that will calculate the F1 score and find the optimal model with the highest F1 score as opposed to the highest accuracy as we did above.</p>
<div class="sourceCode" id="cb475"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb475-1"><a href="supervised-machine-learning.html#cb475-1" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="st">&quot;MLmetrics&quot;</span>)</span>
<span id="cb475-2"><a href="supervised-machine-learning.html#cb475-2" tabindex="-1"></a><span class="fu">library</span>(MLmetrics)</span>
<span id="cb475-3"><a href="supervised-machine-learning.html#cb475-3" tabindex="-1"></a></span>
<span id="cb475-4"><a href="supervised-machine-learning.html#cb475-4" tabindex="-1"></a>f1 <span class="ot">&lt;-</span> <span class="cf">function</span>(data, <span class="at">lev =</span> <span class="cn">NULL</span>, <span class="at">model =</span> <span class="cn">NULL</span>) {</span>
<span id="cb475-5"><a href="supervised-machine-learning.html#cb475-5" tabindex="-1"></a>  <span class="co"># Creating a function to calculate the F1 score</span></span>
<span id="cb475-6"><a href="supervised-machine-learning.html#cb475-6" tabindex="-1"></a>  f1_val <span class="ot">&lt;-</span> <span class="fu">F1_Score</span>(<span class="at">y_pred =</span> data<span class="sc">$</span>pred, <span class="at">y_true =</span> data<span class="sc">$</span>obs, <span class="at">positive =</span> lev[<span class="dv">1</span>])</span>
<span id="cb475-7"><a href="supervised-machine-learning.html#cb475-7" tabindex="-1"></a>  <span class="fu">c</span>(<span class="at">F1 =</span> f1_val)</span>
<span id="cb475-8"><a href="supervised-machine-learning.html#cb475-8" tabindex="-1"></a>}</span>
<span id="cb475-9"><a href="supervised-machine-learning.html#cb475-9" tabindex="-1"></a></span>
<span id="cb475-10"><a href="supervised-machine-learning.html#cb475-10" tabindex="-1"></a><span class="co"># 5 fold CV</span></span>
<span id="cb475-11"><a href="supervised-machine-learning.html#cb475-11" tabindex="-1"></a>ctrl <span class="ot">&lt;-</span> <span class="fu">trainControl</span>(</span>
<span id="cb475-12"><a href="supervised-machine-learning.html#cb475-12" tabindex="-1"></a>  <span class="at">method =</span> <span class="st">&quot;cv&quot;</span>, </span>
<span id="cb475-13"><a href="supervised-machine-learning.html#cb475-13" tabindex="-1"></a>  <span class="at">number =</span> <span class="dv">5</span>,</span>
<span id="cb475-14"><a href="supervised-machine-learning.html#cb475-14" tabindex="-1"></a>  <span class="at">classProbs =</span> <span class="cn">TRUE</span>, </span>
<span id="cb475-15"><a href="supervised-machine-learning.html#cb475-15" tabindex="-1"></a>  <span class="at">summaryFunction =</span> f1</span>
<span id="cb475-16"><a href="supervised-machine-learning.html#cb475-16" tabindex="-1"></a>)</span>
<span id="cb475-17"><a href="supervised-machine-learning.html#cb475-17" tabindex="-1"></a></span>
<span id="cb475-18"><a href="supervised-machine-learning.html#cb475-18" tabindex="-1"></a><span class="co"># Training the RF model</span></span>
<span id="cb475-19"><a href="supervised-machine-learning.html#cb475-19" tabindex="-1"></a>mod <span class="ot">&lt;-</span> <span class="fu">train</span>(<span class="at">x =</span> X,</span>
<span id="cb475-20"><a href="supervised-machine-learning.html#cb475-20" tabindex="-1"></a>             <span class="at">y =</span> Y,</span>
<span id="cb475-21"><a href="supervised-machine-learning.html#cb475-21" tabindex="-1"></a>             <span class="at">trControl =</span> ctrl,</span>
<span id="cb475-22"><a href="supervised-machine-learning.html#cb475-22" tabindex="-1"></a>             <span class="at">method =</span> <span class="st">&quot;rf&quot;</span>,</span>
<span id="cb475-23"><a href="supervised-machine-learning.html#cb475-23" tabindex="-1"></a>             <span class="at">tuneGrid =</span> tunegrid_rf,</span>
<span id="cb475-24"><a href="supervised-machine-learning.html#cb475-24" tabindex="-1"></a>             <span class="at">importance =</span> <span class="cn">TRUE</span>,</span>
<span id="cb475-25"><a href="supervised-machine-learning.html#cb475-25" tabindex="-1"></a>             <span class="co"># Basing the best model performance off of the F1 score within 5 CV</span></span>
<span id="cb475-26"><a href="supervised-machine-learning.html#cb475-26" tabindex="-1"></a>             <span class="at">metric =</span> <span class="st">&quot;F1&quot;</span>)</span></code></pre></div>
<p>For more in-depth information and additional ways to address class imbalance check out <a href="https://medium.com/game-of-bits/how-to-deal-with-imbalanced-data-in-classification-bd03cfc66066">How to Deal with Imbalanced Data in Classification</a>.</p>
<div id="answer-to-environmental-health-question-4-2" class="section level3 hasAnchor">
<h3>Answer to Environmental Health Question 4<a href="supervised-machine-learning.html#answer-to-environmental-health-question-4-2" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="question">
<p><em>With this, we can answer <strong>Environmental Health Question #4</strong></em>: How could this RF model be improved upon, acknowledging that there is class imbalance?</p>
</div>
<div class="answer">
<p><strong>Answer</strong>: We can implement SMOTE to increase the number of training data points for the minority class thereby reducing the class imbalance. In conjunction with using SMOTE, another approach includes selecting an alternative performance metric during training that does a better job taking the existing class imbalance into consideration, such as balanced accuracy or an F1-score, improves our predictive ability for the minority class.</p>
</div>
<p><br></p>
</div>
</div>
<div id="concluding-remarks-18" class="section level2 hasAnchor">
<h2>Concluding Remarks<a href="supervised-machine-learning.html#concluding-remarks-18" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In conclusion, this training module has provided an introduction to supervised machine learning using classification techniques in R. Machine learning is a powerful tool that can help researchers gain new insights and improve models to analyze complex datasets faster and in a more comprehensive way. The example we’ve explored demonstrates the utility of supervised machine learning models on an environmentally relevant dataset.</p>
<p><br></p>
<div id="additional-resources-6" class="section level3 hasAnchor">
<h3>Additional Resources<a href="supervised-machine-learning.html#additional-resources-6" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>To learn more check out the following resources:</p>
<ul>
<li><a href="https://www.ibm.com/topics/machine-learning">IBM - What is Machine Learning</a></li>
<li><a href="https://medium.com/machine-learning-in-practice/my-curated-list-of-ai-and-machine-learning-resources-from-around-the-web-9a97823b8524">Curate List of AI and Machine Learning Resources</a></li>
<li><a href="https://machinelearningmastery.com/machine-learning-in-r-step-by-step/">Introduction to Machine Learning in R</a></li>
<li>Machine Learning by Mueller, J. P. (2021). Machine learning for dummies. John Wiley &amp; Sons.</li>
</ul>
<p><br></p>
<p><label class="tykfont">
Test Your Knowledge
</label></p>
<div class="tyk">
<p>Using the “Module5_2TYKInput.xlsx”, use RF to determine if well water data can be accurate predictors of Manganese detection. The data is structured similarly to the “Module5_2_InputData.xlsx” used in this module, however it now includes 4 additional features:</p>
<ul>
<li><code>Longitude</code>: Longitude of address (decimal degrees)</li>
<li><code>Latitude</code>: Latitude of address (decimal degrees)</li>
<li><code>Stream_Distance</code>: Euclidean distance to the nearest stream (feet)</li>
<li><code>Elevation</code>: Surface elevation of the sample location (feet)</li>
</ul>
</div>
</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="introduction-to-artificial-intelligence-machine-learning-and-predictive-modeling-for-environmental-health.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="supervised-machine-learning-model-interpretation.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["_main.pdf", "_main.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
